{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:27.328195Z","iopub.status.busy":"2024-04-08T12:01:27.327802Z","iopub.status.idle":"2024-04-08T12:01:29.016776Z","shell.execute_reply":"2024-04-08T12:01:29.015800Z","shell.execute_reply.started":"2024-04-08T12:01:27.328163Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch\n","\n","from tqdm import tqdm\n","import numpy as np\n","import os\n","\n","# set seeds for reproducability\n","seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:30.403691Z","iopub.status.busy":"2024-04-08T12:01:30.402707Z","iopub.status.idle":"2024-04-08T12:01:30.408474Z","shell.execute_reply":"2024-04-08T12:01:30.407239Z","shell.execute_reply.started":"2024-04-08T12:01:30.403653Z"},"trusted":true},"outputs":[],"source":["# book collection\n","books = {\n","    'TheOdyssey': (\"TheOdyssey_Homer.txt\", \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/nlp/TheOdyssey_Homer.txt\"),\n","    'PrideAndPrejudice': (\"PrideAndPrejudice_JaneAusten.txt\", \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/nlp/PrideAndPrejudice_JaneAusten.txt\")\n","}"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:30.674710Z","iopub.status.busy":"2024-04-08T12:01:30.674235Z","iopub.status.idle":"2024-04-08T12:01:30.680616Z","shell.execute_reply":"2024-04-08T12:01:30.679571Z","shell.execute_reply.started":"2024-04-08T12:01:30.674680Z"},"trusted":true},"outputs":[],"source":["# choose the book\n","bookname = 'PrideAndPrejudice'\n","\n","# get the book's filename and url \n","book_filename, book_url = books[bookname] \n","\n","# download the book in local if it doesn't already exist\n","if not os.path.exists(book_filename):\n","    !wget $book_url"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:30.961175Z","iopub.status.busy":"2024-04-08T12:01:30.960450Z","iopub.status.idle":"2024-04-08T12:01:30.982717Z","shell.execute_reply":"2024-04-08T12:01:30.981446Z","shell.execute_reply.started":"2024-04-08T12:01:30.961141Z"},"trusted":true},"outputs":[],"source":["# define hyperparameters\n","n_epochs = 10\n","batch_size = 128\n","seq_len = 200\n","learning_rate = 1e-4\n","embed_size = 100\n","hidden_size = 100\n","num_layers = 1\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","best_model_filepath = 'best_model.pt'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:31.271775Z","iopub.status.busy":"2024-04-08T12:01:31.270908Z","iopub.status.idle":"2024-04-08T12:01:31.284486Z","shell.execute_reply":"2024-04-08T12:01:31.283405Z","shell.execute_reply.started":"2024-04-08T12:01:31.271741Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of characters in the text = 690654\n","--------------\n","\n","Sample text:\n"," it\n","was all done very well. She had also to anticipate how her visit would\n","pass, the quiet tenor of their usual employments, the vexatious\n","interruptions of Mr. Collins, and the gaieties of their inter\n","--------------\n","\n"]}],"source":["def load_text(fp):\n","    with open(fp, mode='r') as infile:\n","        text = ''.join([row for row in infile])\n","    return text\n","\n","# load text\n","text = load_text(book_filename)\n","\n","# Get the number of characters in the text\n","text_len = len(text)\n","print(f'Number of characters in the text = {text_len}')\n","print(\"--------------\\n\")\n","\n","# Print a sample from the text\n","idx = np.random.randint(low=0, high=text_len-seq_len)\n","print(f'Sample text:\\n{text[idx:(idx + seq_len)]}')\n","print(\"--------------\\n\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:31.572547Z","iopub.status.busy":"2024-04-08T12:01:31.571381Z","iopub.status.idle":"2024-04-08T12:01:31.590725Z","shell.execute_reply":"2024-04-08T12:01:31.589698Z","shell.execute_reply.started":"2024-04-08T12:01:31.572501Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary: \n"," !\"&'()*,-.1234568:;?ABCDEFGHIJKLMNOPRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyzàê\n","Vocabulary size = 78\n","--------------\n","\n","char 'A' | encode('A') = 22\n","char 'A' | encode(decode('A')) = A\n","--------------\n","\n"]}],"source":["# define vocabulary (set of unique characters in the source text)\n","vocab = sorted(list(set(text)))\n","# get the vocabulary size\n","vocab_size = len(vocab)\n","\n","# define the mappings (as dictionary) of \n","# 'a character (from the vocab) to a unique ID' ---> 'char2int'\n","# and\n","# 'a unique ID to a character (from the vocab)'  ---> 'int2char'\n","char2int = {c: idx for idx, c in enumerate(vocab)}\n","int2char = {idx: c for idx, c in enumerate(vocab)}\n","\n","# define the encode() that encodes/converts a character to a unique ID \n","def encode(character):\n","    global char2int\n","    return char2int[character]\n","\n","# define the encode() that decodes/converts back a unique ID to a character\n","def decode(integer):\n","    global int2char\n","    return int2char[integer]\n","\n","# print vocabulary as a single string \n","print(f\"Vocabulary: {''.join(vocab)}\")\n","print(f\"Vocabulary size = {vocab_size}\")\n","print(\"--------------\\n\")\n","\n","# print an example of how encode() and decode() operate\n","char = 'A'\n","print(f\"char '{char}' | encode('{char}') = {encode(char)}\")\n","print(f\"char '{char}' | decode(encode('{char}')) = {decode(encode(char))}\")\n","print(\"--------------\\n\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:31.873369Z","iopub.status.busy":"2024-04-08T12:01:31.873016Z","iopub.status.idle":"2024-04-08T12:01:31.880533Z","shell.execute_reply":"2024-04-08T12:01:31.879574Z","shell.execute_reply.started":"2024-04-08T12:01:31.873342Z"},"trusted":true},"outputs":[],"source":["# create a dataset for the data as an instance of torch.nn.Dataset class\n","class TextDataset(Dataset):\n","    def __init__(self, text, seq_len):\n","        super().__init__()\n","        self.text = text\n","        self.seq_len = seq_len\n","\n","    def __len__(self):\n","        # define the number of samples in the dataset\n","        return len(self.text) - self.seq_len - 1\n","\n","    def __getitem__(self, idx):\n","        # define the input and target samples\n","        x = torch.tensor([encode(char) for char in self.text[idx:(idx + self.seq_len)]], dtype=torch.long)\n","        y = torch.tensor([encode(char) for char in self.text[(idx + 1):(idx + 1 + self.seq_len)]], dtype=torch.long)\n","        return x, y"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:32.196021Z","iopub.status.busy":"2024-04-08T12:01:32.195624Z","iopub.status.idle":"2024-04-08T12:01:32.202900Z","shell.execute_reply":"2024-04-08T12:01:32.201880Z","shell.execute_reply.started":"2024-04-08T12:01:32.195990Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of the train text = 552524\n","Length of the test text  = 138130\n"]}],"source":["# define test set ratio\n","test_size = 0.2\n","\n","# define the train and test data\n","train_data = text[:-(int(text_len * test_size))]\n","test_data = text[-(int(text_len * test_size)):]\n","\n","# print the length of train and test data\n","print(f'Length of the train text = {len(train_data)}')\n","print(f'Length of the test text  = {len(test_data)}')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:32.527114Z","iopub.status.busy":"2024-04-08T12:01:32.526757Z","iopub.status.idle":"2024-04-08T12:01:32.532616Z","shell.execute_reply":"2024-04-08T12:01:32.531642Z","shell.execute_reply.started":"2024-04-08T12:01:32.527085Z"},"trusted":true},"outputs":[],"source":["# initialize train and test datasets\n","train_dset = TextDataset(train_data, seq_len)\n","test_dset = TextDataset(test_data, seq_len)\n","\n","# initialize train and test iterators\n","train_iterator = DataLoader(train_dset, batch_size, shuffle=True, drop_last=True)\n","test_iterator = DataLoader(test_dset, batch_size, shuffle=False, drop_last=True)  # no need to shuffle the test dset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:32.878442Z","iopub.status.busy":"2024-04-08T12:01:32.878080Z","iopub.status.idle":"2024-04-08T12:01:32.886880Z","shell.execute_reply":"2024-04-08T12:01:32.885777Z","shell.execute_reply.started":"2024-04-08T12:01:32.878413Z"},"trusted":true},"outputs":[],"source":["# define characterRNN module\n","class characterRNN(nn.Module):\n","    def __init__(self, input_size, embed_size, hidden_size, num_layers, output_size):\n","        super().__init__()  \n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.embedding_layer = nn.Embedding(input_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden_state, cell_state):\n","        x = self.embedding_layer(x)\n","        x, (hidden_state, cell_state) = self.lstm(x, (hidden_state, cell_state))\n","        x = self.fc(x)\n","        return x, hidden_state, cell_state\n","    \n","    def init_hidden_and_cell(self, batch_size):\n","        # set the initial hidden and cell state tensors for LSTM training\n","        hidden_state = torch.zeros((self.num_layers, batch_size, hidden_size))\n","        cell_state = torch.zeros((self.num_layers, batch_size, hidden_size))\n","        return hidden_state, cell_state"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:33.284708Z","iopub.status.busy":"2024-04-08T12:01:33.284359Z","iopub.status.idle":"2024-04-08T12:01:33.292681Z","shell.execute_reply":"2024-04-08T12:01:33.291642Z","shell.execute_reply.started":"2024-04-08T12:01:33.284680Z"},"trusted":true},"outputs":[],"source":["def generate_text(model, start_char='\\n', generated_text_len=200, temperature=0.8):\n","    \n","    global device\n","    \n","    # set model to train mode\n","    model.eval()\n","    \n","    # add start character to the beginning of the generated text sequence\n","    generated_text = start_char\n","    \n","    # operate under inference mode to avoid gradient computations and speed up the process\n","    with torch.inference_mode():\n","        # set the initial hidden and cell state tensors for LSTM training\n","        hidden_state, cell_state = model.init_hidden_and_cell(batch_size=1)\n","        hidden_state, cell_state = hidden_state.to(device), cell_state.to(device)\n","        \n","        # encode the start_char and reshape by adding a single batch dimensionality \n","        x = torch.tensor(encode(start_char), dtype=torch.long).view(1, -1).to(device)\n","        \n","        # generate N characters, where N = generated_text_len\n","        for _ in range(generated_text_len):\n","            # predict the probabilities of the next character\n","            y, hidden_state, cell_state = model(x, hidden_state, cell_state)\n","            # select the next character from a multinomial distribution\n","            # (descreasing temperature value provides more flexibility for the next character selection and vice versa)\n","            x = torch.multinomial(y[0].div(temperature).exp(), num_samples=1)            \n","            # decode the next character (for human readibility) \n","            next_char = decode(x.item())\n","            # add next character to the end of the generated text\n","            generated_text += next_char\n","\n","    return generated_text"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:34.022059Z","iopub.status.busy":"2024-04-08T12:01:34.021310Z","iopub.status.idle":"2024-04-08T12:01:34.030075Z","shell.execute_reply":"2024-04-08T12:01:34.028919Z","shell.execute_reply.started":"2024-04-08T12:01:34.022028Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, iterator):\n","    \n","    global device\n","    \n","    # set model to train mode\n","    model.eval()\n","    \n","    # operate under inference mode to avoid gradient computations and speed up the process\n","    with torch.inference_mode():\n","        # initialize loss\n","        loss_sum = 0.0\n","        \n","        # iterate over batches\n","        for x, y in tqdm(iterator):\n","            # carry tensors to selected device\n","            x, y = x.to(device), y.to(device)\n","\n","            # set the initial hidden and cell state tensors for LSTM training\n","            hidden_state, cell_state = model.init_hidden_and_cell(batch_size)\n","            hidden_state, cell_state = hidden_state.to(device), cell_state.to(device)\n","\n","            # forward pass (get logits, hidden and cell states for each characters in the sequence)\n","            logits, hidden_state, cell_state = model(x, hidden_state, cell_state)\n","\n","            # compute loss (cross entropy) for each characters in the sequence (take average at the end)\n","            seq_len = len(x)\n","            loss = torch.mean(torch.stack([F.cross_entropy(logits[:,i,:], y[:,i]) for i in range(seq_len)]))\n","            \n","            # add batch loss to total loss sum\n","            loss_sum += loss.item()\n","    \n","    # compute avg loss\n","    loss_avg = loss_sum / len(iterator)\n","    return loss_avg"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T12:01:34.611118Z","iopub.status.busy":"2024-04-08T12:01:34.610186Z","iopub.status.idle":"2024-04-08T12:57:45.332973Z","shell.execute_reply":"2024-04-08T12:57:45.331972Z","shell.execute_reply.started":"2024-04-08T12:01:34.611083Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:08<00:00, 13.99it/s]\n","100%|██████████| 1077/1077 [00:29<00:00, 37.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 1 || train loss = 2.191\ttest loss = 1.737\n","\n","\n"," day formering he fortur an septiaging the this genked at am my her parly to have pould was the could he vay it seepe veray of her itherd be inded, and, she to mucis mishise, as and a the not am that be hit the himsur presest to the frome the not been; turct the masted, and nation mut were of her earce, and with at it any wass insorqued at latt to porceref what be fist reated what companted the to the firged, ow not added to and Mr. Shan the\n","prast you for wha into must on of his self thean not D\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.737\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:06<00:00, 14.07it/s]\n","100%|██████████| 1077/1077 [00:28<00:00, 37.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 2 || train loss = 1.566\ttest loss = 1.490\n","\n","\n","the much and she such adsure by the\n","comforts.\n","\n","Elizabets and or her felent with their considel the propite a sing happiness with proonaily sorment; but he will now him difficer's amaughter, there from of your beliest women of such\n","a drest Mr. Darcy the was such have their meanty to the some intlemed by she perfected Longhang, it was in a protage his ofling\n","by I not halment tonear of unders in the lotter's enought be had minder ffor the fatter reltance? I am intrommable been grated to the fupt, t\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.490\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:07<00:00, 14.04it/s]\n","100%|██████████| 1077/1077 [00:28<00:00, 37.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 3 || train loss = 1.403\ttest loss = 1.402\n","\n","\n","\"To leave they were bring the should not be so litter to in it would be on to\n","acquaintancly that be\n","as regave, had allo--be. On that you should be rangerly were alone were excesfle. She had not concess and with of the smost were surporing but enough expressing might will be\n","are nothing of\n","those it was not feelings. \"Wickham, For one that elacial sominned to his few to me in him of your against had near do her uspought I was not courre, of so the dinedness, and particers with being much and happy\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.402\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:08<00:00, 13.99it/s]\n","100%|██████████| 1077/1077 [00:29<00:00, 37.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 4 || train loss = 1.329\ttest loss = 1.360\n","\n","\n","     in his reformer; and if his considered; and she might have never being another proached by\n","     wo do you, it every such all Mr. Bingley was not be hart and\n","soon to just attending to Miss Darcy who had never neect misair, he saming a ratements, carming a wish in his his said, that she certable for the besher before they were cacking to say not have not how freh I they was expression of all the farteld them had pleasure at I gourey; there were certain that Mr. Darcy and Miss Bingley were som\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.360\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:07<00:00, 14.02it/s]\n","100%|██████████| 1077/1077 [00:28<00:00, 37.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 5 || train loss = 1.286\ttest loss = 1.334\n","\n","\n","\n","to _he_ is as her wish to her carriate of her brother, and had not believe might and easily such must propsons; but I should have been seen by\n","the passed her us\n","persuaded the windle; but now had about from the parton, and with the take your mother, \"I shall\n","not mach that they Longbourn than\n","be rememether so father to nothing to think it was each attentions of sister, that\n","I have such a mistach of its now quietiess. Lown Elizabeth, \"they had been so mention with a little being so, he should have\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.334\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:06<00:00, 14.06it/s]\n","100%|██████████| 1077/1077 [00:28<00:00, 37.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 6 || train loss = 1.256\ttest loss = 1.317\n","\n","\n","was\n","me to all five must long, and, he added in Mr. Darcy, and her\n","so consent direful with his manner of the smile of her incontively; but I have been all to Longbourn,\" said\n","Lady Catherine's attanner afterwards to be afterwisely conceities on the presentation which Mr. Wickham had began at the pleased Mr. Darcy with a moment. I want from so many considering her farther to want of the wisely of powers to revery. He was present and bridged to make his soon to be at likely would no more.\"\n","\n","Mr. Gard\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.317\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:09<00:00, 13.93it/s]\n","100%|██████████| 1077/1077 [00:28<00:00, 37.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 7 || train loss = 1.233\ttest loss = 1.306\n","\n","\n","\n","and her resent that the subject of the whole procient, to go me, you will any often been undertoning to the charge of a lought, and particularly to speaks, they will not\n","suppose of she brother, and so beauty.\"\n","\n","\"My dear very short ender the last your confidial, he was not subseding them, know it over see. Mr. Collins had not?\"\n","\n","\"We assured Elizabeth, \"what answer the boths.\"\n","\n","\"No, last that I have in the kinding with them all the wishes of herself, replied speated. Sir Denny Mrs. Bennet have ju\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.306\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:07<00:00, 14.03it/s]\n","100%|██████████| 1077/1077 [00:28<00:00, 37.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 8 || train loss = 1.216\ttest loss = 1.298\n","\n","\n","wat\n","morning it. Her mother sent played to her, or a fancy of the first entuence which had nothing to be her agreeable for herself.\"\n","\n","Elizabeth almost silent that contriety to respect, and from the country, had so firm, he had been glad to met the country stair propertly with her own on\n","event to deter of\n","some good\n","man\n","are nothing which was inhabour to make of with a consisting him, thought the door.\n","\n","Mrs. Bennet,\n","the carriage had lively but the late on one on the room, when I\n","have love at Netherf\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.298\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:07<00:00, 14.04it/s]\n","100%|██████████| 1077/1077 [00:28<00:00, 37.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 9 || train loss = 1.202\ttest loss = 1.293\n","\n","\n","      for your facely bestone, I shall all the subject,\" said\n","Elizabeth, and the laws proves to answer.\"\n","\n","\"Perhaps would be as whose had a call of prover four sister in the unfier for the charms were the Parsonage, and all bestow, however, indeed brought or asking\n","much as she replied?\"\n","\n","\"I do below who had then strike enjoying the good was next perios which the particulars the near mewn, there is a disportagly\n","she could not at least afterwards or accomplished with a rates to glad to her it. The \n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.293\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4315/4315 [05:08<00:00, 13.98it/s]\n","100%|██████████| 1077/1077 [00:29<00:00, 37.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch 10 || train loss = 1.190\ttest loss = 1.289\n","\n","\n","     persuating Mr. Collins was a\n","character with a pride again that is concerned in the rest or a comparable regarded by pleasure might\n","have a laugh as pleasant written at restory, she may have been going to the first not to lear how your land; and, and subject, there concerned to Elizabeth himself that you into do not the so look of the difference,\"\n","said Mrs.\n","Forster. The lost of her partly intention of many great could past as his very then worth, were made unavoid of the little partiality,\n","an\n","--------------\n","\n","The best model is found and saved. Current best test loss = 1.289\n"]}],"source":["# initialize characterRNN model\n","model = characterRNN(\n","    input_size=vocab_size,\n","    embed_size=embed_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    output_size=vocab_size,\n",").to(device)\n","\n","# initialize the optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# init the best test loss as positive inifinity\n","best_test_loss = float('inf')\n","\n","###### training loop ######\n","# iterate over epochs\n","for epoch_idx in range(1, n_epochs+1):\n","    # set model to train mode\n","    model.train()  \n","    \n","    loss_train = 0.0\n","    # iterate over batches        \n","    for iter_idx, (x, y) in tqdm(enumerate(train_iterator), total=len(train_iterator)):  \n","        # carry tensors to selected device\n","        x, y = x.to(device), y.to(device)\n","        \n","        # set the initial hidden and cell state tensors for LSTM training\n","        hidden_state, cell_state = model.init_hidden_and_cell(batch_size)\n","        hidden_state, cell_state = hidden_state.to(device), cell_state.to(device)\n","                \n","        # forward pass (get logits, hidden and cell states for each characters in the sequence)\n","        logits, hidden_state, cell_state = model(x, hidden_state, cell_state)\n","        \n","        # compute loss (cross entropy) for each characters in the sequence (take average at the end)\n","        loss = torch.mean(torch.stack([F.cross_entropy(logits[:,i,:], y[:,i]) for i in range(seq_len)]))\n","        \n","        # update gradients\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # add batch loss to total loss sum\n","        loss_train += loss.item()\n","        \n","    # at the end of each epoch, generate a text and display\n","    loss_train /= len(train_iterator)\n","    loss_test = evaluate(model, test_iterator)\n","    print(f\"epoch {epoch_idx} || train loss = {loss_train:.3f}\\ttest loss = {loss_test:.3f}\\n\")\n","    print(generate_text(model, generated_text_len=500))\n","    print(\"--------------\\n\")\n","    \n","    # save the current model as the best model if the current test loss is the least achieved \n","    if loss_test < best_test_loss:\n","        # save the curent model's parameters as the best model parameters\n","        torch.save(model.state_dict(), best_model_filepath)\n","        # replace the best test loss with the current best loss\n","        best_test_loss = loss_test\n","        # display info\n","        print(f'The best model is found and saved. Current best test loss = {best_test_loss:.3f}')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T13:03:30.310106Z","iopub.status.busy":"2024-04-08T13:03:30.309723Z","iopub.status.idle":"2024-04-08T13:03:30.320968Z","shell.execute_reply":"2024-04-08T13:03:30.320192Z","shell.execute_reply.started":"2024-04-08T13:03:30.310075Z"},"trusted":true},"outputs":[],"source":["### loading the best model\n","\n","# reinitialize the model\n","best_model = characterRNN(\n","    input_size=vocab_size,\n","    embed_size=embed_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    output_size=vocab_size,\n",")\n","# load best model's parameters\n","best_model.load_state_dict(torch.load(best_model_filepath))\n","best_model = best_model.to(device)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T13:03:30.617768Z","iopub.status.busy":"2024-04-08T13:03:30.617410Z","iopub.status.idle":"2024-04-08T13:03:32.007082Z","shell.execute_reply":"2024-04-08T13:03:32.006204Z","shell.execute_reply.started":"2024-04-08T13:03:30.617738Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Temperature = 1.0\n","\n","only, which as.\" Miss Bingley. Her Lady Catherine\n","and his niece. There is sister that I have all that we may look you, necessanot, she saw. Thought. It told it. Whilley next of summe, she took happiness that she were it was now again as much was being enterledness Sit astonishat\n","oming\n","trough probably to arved that he would not you case him tilling as to desirit example\n","as,\n","I wish a desire does pleasure in termities of the estates interest of glander way, convince.--What she deare, with for any deady often; and if could not going much following knew to be ideedial to have knows what I very from thinking one of this favoured to his regard to believe and perfect by elegance had\n","been one so approaching to see must only are\n","subject, I _mind_ exached on the\n","evowly.\"\n","\n","\"She is not satisf own many in the formpaking did so misuralice to play to her disposition with the\n","house, as her uncle are, all the whole interest\n","other give, by nead very attemon her ainder the same slighted.--Nay, than he les\n","--------------\n","\n","\n","Temperature = 0.8\n","\n","quite intemove me to the girls to think it in enough on the day, which she could have known to think whole proper of the house at\n","the plainly always so mention of mind, on their compliments. Mr. Darcy should never wish the expression to her father to the present of himself in love?--you do be attention of different\n","introduce it would be conversation of so manner with the complain the distress which could\n","not take the considerable must did she acknowledge in thise assured may he will be\n","alone at or accusit, and may to wish to what you must be rejection for it.\"\n","\n","\"Mr. Darcy had leave when all.\"\n","\n","\"You and the world has obliged to the confidence of it to be manner, however since chose of the evident as happensing sure of something of his side, are their intended therefore, her promople of read that the think who have company had been more carm of with the intimates, and be for all difference in pleasure to a very concern as she\n","is these. Elizabeth feather.\n","\n","\"I do seen you are stund apprope\n","--------------\n","\n","\n","Temperature = 0.5\n","\n","\n","     \"Mr. Wickham was a little because it was most account of his endeavour to her handsome was the other\n","soon account of the same surprise what had been some countenance. I cannot be surprised to be a settled to her sisters were about the house of the other feelings and happiness of her father was such a proud, and was such a settled to make to be so little less being one of her considerable the family was to be a settled after a large was the letter and valued me to the day to his\n","asure with the particularly eldest as all the evening and consisted again, and who should not dance of the best of the silence of such a great most near her attention of the things to be in the subject of her sister, and made not conceal the stronger of his advantage of her attention of the room of her evening and often and say to him with the less all the conversation was some attentions of the country of the determined to what she was to make her to sit in the particular usual sensible his sister, and sh\n","--------------\n","\n","\n"]}],"source":["### generating text with different temperature values \n","### (descreasing temperature value provides more flexibility for the next character selection (tends to generate low-quality but more creative texts) and vice versa)\n","\n","# define possible temperature values\n","temperatures = [1.0, 0.8, 0.5]\n","\n","# iterate over temperature values\n","for temp in temperatures:\n","    # generate text\n","    generated_test = generate_text(best_model, generated_text_len=1000, temperature=temp)\n","    # display\n","    print(f'Temperature = {temp}')\n","    print(generated_test)\n","    print(\"--------------\\n\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
