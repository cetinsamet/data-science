{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\n\nfrom tqdm import tqdm\nimport numpy as np\nimport os\n\n# set seeds for reproducability\nseed = 123\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:27.327802Z","iopub.execute_input":"2024-04-08T12:01:27.328195Z","iopub.status.idle":"2024-04-08T12:01:29.016776Z","shell.execute_reply.started":"2024-04-08T12:01:27.328163Z","shell.execute_reply":"2024-04-08T12:01:29.015800Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# book collection\nbooks = {\n    'TheOdyssey': (\"TheOdyssey_Homer.txt\", \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/nlp/TheOdyssey_Homer.txt\"),\n    'PrideAndPrejudice': (\"PrideAndPrejudice_JaneAusten.txt\", \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/nlp/PrideAndPrejudice_JaneAusten.txt\")\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:30.402707Z","iopub.execute_input":"2024-04-08T12:01:30.403691Z","iopub.status.idle":"2024-04-08T12:01:30.408474Z","shell.execute_reply.started":"2024-04-08T12:01:30.403653Z","shell.execute_reply":"2024-04-08T12:01:30.407239Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# choose the book\nbookname = 'PrideAndPrejudice'\n\n# get the book's filename and url \nbook_filename, book_url = books[bookname] \n\n# download the book in local if it doesn't already exist\nif not os.path.exists(book_filename):\n    !wget $book_url","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:30.674235Z","iopub.execute_input":"2024-04-08T12:01:30.674710Z","iopub.status.idle":"2024-04-08T12:01:30.680616Z","shell.execute_reply.started":"2024-04-08T12:01:30.674680Z","shell.execute_reply":"2024-04-08T12:01:30.679571Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# define hyperparameters\nn_epochs = 10\nbatch_size = 128\nseq_len = 200\nlearning_rate = 1e-4\nembed_size = 100\nhidden_size = 100\nnum_layers = 1\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_model_filepath = 'best_model.pt'","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:30.960450Z","iopub.execute_input":"2024-04-08T12:01:30.961175Z","iopub.status.idle":"2024-04-08T12:01:30.982717Z","shell.execute_reply.started":"2024-04-08T12:01:30.961141Z","shell.execute_reply":"2024-04-08T12:01:30.981446Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_text(fp):\n    with open(fp, mode='r') as infile:\n        text = ''.join([row for row in infile])\n    return text\n\n# load text\ntext = load_text(book_filename)\n\n# Get the number of characters in the text\ntext_len = len(text)\nprint(f'Number of characters in the text = {text_len}')\nprint(\"--------------\\n\")\n\n# Print a sample from the text\nidx = np.random.randint(low=0, high=text_len-seq_len)\nprint(f'Sample text:\\n{text[idx:(idx + seq_len)]}')\nprint(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:31.270908Z","iopub.execute_input":"2024-04-08T12:01:31.271775Z","iopub.status.idle":"2024-04-08T12:01:31.284486Z","shell.execute_reply.started":"2024-04-08T12:01:31.271741Z","shell.execute_reply":"2024-04-08T12:01:31.283405Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Number of characters in the text = 690654\n--------------\n\nSample text:\n it\nwas all done very well. She had also to anticipate how her visit would\npass, the quiet tenor of their usual employments, the vexatious\ninterruptions of Mr. Collins, and the gaieties of their inter\n--------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# define vocabulary (set of unique characters in the source text)\nvocab = sorted(list(set(text)))\n# get the vocabulary size\nvocab_size = len(vocab)\n\n# define the mappings (as dictionary) of \n# 'a character (from the vocab) to a unique ID' ---> 'char2int'\n# and\n# 'a unique ID to a character (from the vocab)'  ---> 'int2char'\nchar2int = {c: idx for idx, c in enumerate(vocab)}\nint2char = {idx: c for idx, c in enumerate(vocab)}\n\n# define the encode() that encodes/converts a character to a unique ID \ndef encode(character):\n    global char2int\n    return char2int[character]\n\n# define the encode() that decodes/converts back a unique ID to a character\ndef decode(integer):\n    global int2char\n    return int2char[integer]\n\n# print vocabulary as a single string \nprint(f\"Vocabulary: {''.join(vocab)}\")\nprint(f\"Vocabulary size = {vocab_size}\")\nprint(\"--------------\\n\")\n\n# print an example of how encode() and decode() operate\nchar = 'A'\nprint(f\"char '{char}' | encode('{char}') = {encode(char)}\")\nprint(f\"char '{char}' | encode(decode('{char}')) = {decode(encode(char))}\")\nprint(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:31.571381Z","iopub.execute_input":"2024-04-08T12:01:31.572547Z","iopub.status.idle":"2024-04-08T12:01:31.590725Z","shell.execute_reply.started":"2024-04-08T12:01:31.572501Z","shell.execute_reply":"2024-04-08T12:01:31.589698Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Vocabulary: \n !\"&'()*,-.1234568:;?ABCDEFGHIJKLMNOPRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyzàê\nVocabulary size = 78\n--------------\n\nchar 'A' | encode('A') = 22\nchar 'A' | encode(decode('A')) = A\n--------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a dataset for the data as an instance of torch.nn.Dataset class\nclass TextDataset(Dataset):\n    def __init__(self, text, seq_len):\n        super().__init__()\n        self.text = text\n        self.seq_len = seq_len\n\n    def __len__(self):\n        # define the number of samples in the dataset\n        return len(self.text) - self.seq_len - 1\n\n    def __getitem__(self, idx):\n        # define the input and target samples\n        x = torch.tensor([encode(char) for char in self.text[idx:(idx + self.seq_len)]], dtype=torch.long)\n        y = torch.tensor([encode(char) for char in self.text[(idx + 1):(idx + 1 + self.seq_len)]], dtype=torch.long)\n        return x, y","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:31.873016Z","iopub.execute_input":"2024-04-08T12:01:31.873369Z","iopub.status.idle":"2024-04-08T12:01:31.880533Z","shell.execute_reply.started":"2024-04-08T12:01:31.873342Z","shell.execute_reply":"2024-04-08T12:01:31.879574Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# define test set ratio\ntest_size = 0.2\n\n# define the train and test data\ntrain_data = text[:-(int(text_len * test_size))]\ntest_data = text[-(int(text_len * test_size)):]\n\n# print the length of train and test data\nprint(f'Length of the train text = {len(train_data)}')\nprint(f'Length of the test text  = {len(test_data)}')","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:32.195624Z","iopub.execute_input":"2024-04-08T12:01:32.196021Z","iopub.status.idle":"2024-04-08T12:01:32.202900Z","shell.execute_reply.started":"2024-04-08T12:01:32.195990Z","shell.execute_reply":"2024-04-08T12:01:32.201880Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Length of the train text = 552524\nLength of the test text  = 138130\n","output_type":"stream"}]},{"cell_type":"code","source":"# initialize train and test datasets\ntrain_dset = TextDataset(train_data, seq_len)\ntest_dset = TextDataset(test_data, seq_len)\n\n# initialize train and test iterators\ntrain_iterator = DataLoader(train_dset, batch_size, shuffle=True, drop_last=True)\ntest_iterator = DataLoader(test_dset, batch_size, shuffle=False, drop_last=True)  # no need to shuffle the test dset","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:32.526757Z","iopub.execute_input":"2024-04-08T12:01:32.527114Z","iopub.status.idle":"2024-04-08T12:01:32.532616Z","shell.execute_reply.started":"2024-04-08T12:01:32.527085Z","shell.execute_reply":"2024-04-08T12:01:32.531642Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# define characterRNN module\nclass characterRNN(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers, output_size):\n        super().__init__()  \n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        self.embedding_layer = nn.Embedding(input_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden_state, cell_state):\n        x = self.embedding_layer(x)\n        x, (hidden_state, cell_state) = self.lstm(x, (hidden_state, cell_state))\n        x = self.fc(x)\n        return x, hidden_state, cell_state\n    \n    def init_hidden_and_cell(self, batch_size):\n        # set the initial hidden and cell state tensors for LSTM training\n        hidden_state = torch.zeros((self.num_layers, batch_size, hidden_size))\n        cell_state = torch.zeros((self.num_layers, batch_size, hidden_size))\n        return hidden_state, cell_state","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:32.878080Z","iopub.execute_input":"2024-04-08T12:01:32.878442Z","iopub.status.idle":"2024-04-08T12:01:32.886880Z","shell.execute_reply.started":"2024-04-08T12:01:32.878413Z","shell.execute_reply":"2024-04-08T12:01:32.885777Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def generate_text(model, start_char='\\n', generated_text_len=200, temperature=0.8):\n    \n    global device\n    \n    # set model to train mode\n    model.eval()\n    \n    # add start character to the beginning of the generated text sequence\n    generated_text = start_char\n    \n    # operate under inference mode to avoid gradient computations and speed up the process\n    with torch.inference_mode():\n        # set the initial hidden and cell state tensors for LSTM training\n        hidden_state, cell_state = model.init_hidden_and_cell(batch_size=1)\n        hidden_state, cell_state = hidden_state.to(device), cell_state.to(device)\n        \n        # encode the start_char and reshape by adding a single batch dimensionality \n        x = torch.tensor(encode(start_char), dtype=torch.long).view(1, -1).to(device)\n        \n        # generate N characters, where N = generated_text_len\n        for _ in range(generated_text_len):\n            # predict the probabilities of the next character\n            y, hidden_state, cell_state = model(x, hidden_state, cell_state)\n            # select the next character from a multinomial distribution\n            # (descreasing temperature value provides more flexibility for the next character selection and vice versa)\n            x = torch.multinomial(y[0].div(temperature).exp(), num_samples=1)            \n            # decode the next character (for human readibility) \n            next_char = decode(x.item())\n            # add next character to the end of the generated text\n            generated_text += next_char\n\n    return generated_text","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:33.284359Z","iopub.execute_input":"2024-04-08T12:01:33.284708Z","iopub.status.idle":"2024-04-08T12:01:33.292681Z","shell.execute_reply.started":"2024-04-08T12:01:33.284680Z","shell.execute_reply":"2024-04-08T12:01:33.291642Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator):\n    \n    global device\n    \n    # set model to train mode\n    model.eval()\n    \n    # operate under inference mode to avoid gradient computations and speed up the process\n    with torch.inference_mode():\n        # initialize loss\n        loss_sum = 0.0\n        \n        # iterate over batches\n        for x, y in tqdm(iterator):\n            # carry tensors to selected device\n            x, y = x.to(device), y.to(device)\n\n            # set the initial hidden and cell state tensors for LSTM training\n            hidden_state, cell_state = model.init_hidden_and_cell(batch_size)\n            hidden_state, cell_state = hidden_state.to(device), cell_state.to(device)\n\n            # forward pass (get logits, hidden and cell states for each characters in the sequence)\n            logits, hidden_state, cell_state = model(x, hidden_state, cell_state)\n\n            # compute loss (cross entropy) for each characters in the sequence (take average at the end)\n            seq_len = len(x)\n            loss = torch.mean(torch.stack([F.cross_entropy(logits[:,i,:], y[:,i]) for i in range(seq_len)]))\n            \n            # add batch loss to total loss sum\n            loss_sum += loss.item()\n    \n    # compute avg loss\n    loss_avg = loss_sum / len(iterator)\n    return loss_avg","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:34.021310Z","iopub.execute_input":"2024-04-08T12:01:34.022059Z","iopub.status.idle":"2024-04-08T12:01:34.030075Z","shell.execute_reply.started":"2024-04-08T12:01:34.022028Z","shell.execute_reply":"2024-04-08T12:01:34.028919Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# initialize characterRNN model\nmodel = characterRNN(\n    input_size=vocab_size,\n    embed_size=embed_size,\n    hidden_size=hidden_size,\n    num_layers=num_layers,\n    output_size=vocab_size,\n).to(device)\n\n# initialize the optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# init the best test loss as positive inifinity\nbest_test_loss = float('inf')\n\n###### training loop ######\n# iterate over epochs\nfor epoch_idx in range(1, n_epochs+1):\n    # set model to train mode\n    model.train()  \n    \n    loss_train = 0.0\n    # iterate over batches        \n    for iter_idx, (x, y) in tqdm(enumerate(train_iterator), total=len(train_iterator)):  \n        # carry tensors to selected device\n        x, y = x.to(device), y.to(device)\n        \n        # set the initial hidden and cell state tensors for LSTM training\n        hidden_state, cell_state = model.init_hidden_and_cell(batch_size)\n        hidden_state, cell_state = hidden_state.to(device), cell_state.to(device)\n                \n        # forward pass (get logits, hidden and cell states for each characters in the sequence)\n        logits, hidden_state, cell_state = model(x, hidden_state, cell_state)\n        \n        # compute loss (cross entropy) for each characters in the sequence (take average at the end)\n        loss = torch.mean(torch.stack([F.cross_entropy(logits[:,i,:], y[:,i]) for i in range(seq_len)]))\n        \n        # update gradients\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # add batch loss to total loss sum\n        loss_train += loss.item()\n        \n    # at the end of each epoch, generate a text and display\n    loss_train /= len(train_iterator)\n    loss_test = evaluate(model, test_iterator)\n    print(f\"epoch {epoch_idx} || train loss = {loss_train:.3f}\\ttest loss = {loss_test:.3f}\\n\")\n    print(generate_text(model, generated_text_len=500))\n    print(\"--------------\\n\")\n    \n    # save the current model as the best model if the current test loss is the least achieved \n    if loss_test < best_test_loss:\n        # save the curent model's parameters as the best model parameters\n        torch.save(model.state_dict(), best_model_filepath)\n        # replace the best test loss with the current best loss\n        best_test_loss = loss_test\n        # display info\n        print(f'The best model is found and saved. Current best test loss = {best_test_loss:.3f}')","metadata":{"execution":{"iopub.status.busy":"2024-04-08T12:01:34.610186Z","iopub.execute_input":"2024-04-08T12:01:34.611118Z","iopub.status.idle":"2024-04-08T12:57:45.332973Z","shell.execute_reply.started":"2024-04-08T12:01:34.611083Z","shell.execute_reply":"2024-04-08T12:57:45.331972Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 4315/4315 [05:08<00:00, 13.99it/s]\n100%|██████████| 1077/1077 [00:29<00:00, 37.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 1 || train loss = 2.191\ttest loss = 1.737\n\n\n day formering he fortur an septiaging the this genked at am my her parly to have pould was the could he vay it seepe veray of her itherd be inded, and, she to mucis mishise, as and a the not am that be hit the himsur presest to the frome the not been; turct the masted, and nation mut were of her earce, and with at it any wass insorqued at latt to porceref what be fist reated what companted the to the firged, ow not added to and Mr. Shan the\nprast you for wha into must on of his self thean not D\n--------------\n\nThe best model is found and saved. Current best test loss = 1.737\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:06<00:00, 14.07it/s]\n100%|██████████| 1077/1077 [00:28<00:00, 37.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 2 || train loss = 1.566\ttest loss = 1.490\n\n\nthe much and she such adsure by the\ncomforts.\n\nElizabets and or her felent with their considel the propite a sing happiness with proonaily sorment; but he will now him difficer's amaughter, there from of your beliest women of such\na drest Mr. Darcy the was such have their meanty to the some intlemed by she perfected Longhang, it was in a protage his ofling\nby I not halment tonear of unders in the lotter's enought be had minder ffor the fatter reltance? I am intrommable been grated to the fupt, t\n--------------\n\nThe best model is found and saved. Current best test loss = 1.490\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:07<00:00, 14.04it/s]\n100%|██████████| 1077/1077 [00:28<00:00, 37.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 3 || train loss = 1.403\ttest loss = 1.402\n\n\n\"To leave they were bring the should not be so litter to in it would be on to\nacquaintancly that be\nas regave, had allo--be. On that you should be rangerly were alone were excesfle. She had not concess and with of the smost were surporing but enough expressing might will be\nare nothing of\nthose it was not feelings. \"Wickham, For one that elacial sominned to his few to me in him of your against had near do her uspought I was not courre, of so the dinedness, and particers with being much and happy\n--------------\n\nThe best model is found and saved. Current best test loss = 1.402\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:08<00:00, 13.99it/s]\n100%|██████████| 1077/1077 [00:29<00:00, 37.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 4 || train loss = 1.329\ttest loss = 1.360\n\n\n     in his reformer; and if his considered; and she might have never being another proached by\n     wo do you, it every such all Mr. Bingley was not be hart and\nsoon to just attending to Miss Darcy who had never neect misair, he saming a ratements, carming a wish in his his said, that she certable for the besher before they were cacking to say not have not how freh I they was expression of all the farteld them had pleasure at I gourey; there were certain that Mr. Darcy and Miss Bingley were som\n--------------\n\nThe best model is found and saved. Current best test loss = 1.360\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:07<00:00, 14.02it/s]\n100%|██████████| 1077/1077 [00:28<00:00, 37.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 5 || train loss = 1.286\ttest loss = 1.334\n\n\n\nto _he_ is as her wish to her carriate of her brother, and had not believe might and easily such must propsons; but I should have been seen by\nthe passed her us\npersuaded the windle; but now had about from the parton, and with the take your mother, \"I shall\nnot mach that they Longbourn than\nbe rememether so father to nothing to think it was each attentions of sister, that\nI have such a mistach of its now quietiess. Lown Elizabeth, \"they had been so mention with a little being so, he should have\n--------------\n\nThe best model is found and saved. Current best test loss = 1.334\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:06<00:00, 14.06it/s]\n100%|██████████| 1077/1077 [00:28<00:00, 37.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 6 || train loss = 1.256\ttest loss = 1.317\n\n\nwas\nme to all five must long, and, he added in Mr. Darcy, and her\nso consent direful with his manner of the smile of her incontively; but I have been all to Longbourn,\" said\nLady Catherine's attanner afterwards to be afterwisely conceities on the presentation which Mr. Wickham had began at the pleased Mr. Darcy with a moment. I want from so many considering her farther to want of the wisely of powers to revery. He was present and bridged to make his soon to be at likely would no more.\"\n\nMr. Gard\n--------------\n\nThe best model is found and saved. Current best test loss = 1.317\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:09<00:00, 13.93it/s]\n100%|██████████| 1077/1077 [00:28<00:00, 37.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 7 || train loss = 1.233\ttest loss = 1.306\n\n\n\nand her resent that the subject of the whole procient, to go me, you will any often been undertoning to the charge of a lought, and particularly to speaks, they will not\nsuppose of she brother, and so beauty.\"\n\n\"My dear very short ender the last your confidial, he was not subseding them, know it over see. Mr. Collins had not?\"\n\n\"We assured Elizabeth, \"what answer the boths.\"\n\n\"No, last that I have in the kinding with them all the wishes of herself, replied speated. Sir Denny Mrs. Bennet have ju\n--------------\n\nThe best model is found and saved. Current best test loss = 1.306\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:07<00:00, 14.03it/s]\n100%|██████████| 1077/1077 [00:28<00:00, 37.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 8 || train loss = 1.216\ttest loss = 1.298\n\n\nwat\nmorning it. Her mother sent played to her, or a fancy of the first entuence which had nothing to be her agreeable for herself.\"\n\nElizabeth almost silent that contriety to respect, and from the country, had so firm, he had been glad to met the country stair propertly with her own on\nevent to deter of\nsome good\nman\nare nothing which was inhabour to make of with a consisting him, thought the door.\n\nMrs. Bennet,\nthe carriage had lively but the late on one on the room, when I\nhave love at Netherf\n--------------\n\nThe best model is found and saved. Current best test loss = 1.298\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:07<00:00, 14.04it/s]\n100%|██████████| 1077/1077 [00:28<00:00, 37.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 9 || train loss = 1.202\ttest loss = 1.293\n\n\n      for your facely bestone, I shall all the subject,\" said\nElizabeth, and the laws proves to answer.\"\n\n\"Perhaps would be as whose had a call of prover four sister in the unfier for the charms were the Parsonage, and all bestow, however, indeed brought or asking\nmuch as she replied?\"\n\n\"I do below who had then strike enjoying the good was next perios which the particulars the near mewn, there is a disportagly\nshe could not at least afterwards or accomplished with a rates to glad to her it. The \n--------------\n\nThe best model is found and saved. Current best test loss = 1.293\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [05:08<00:00, 13.98it/s]\n100%|██████████| 1077/1077 [00:29<00:00, 37.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 10 || train loss = 1.190\ttest loss = 1.289\n\n\n     persuating Mr. Collins was a\ncharacter with a pride again that is concerned in the rest or a comparable regarded by pleasure might\nhave a laugh as pleasant written at restory, she may have been going to the first not to lear how your land; and, and subject, there concerned to Elizabeth himself that you into do not the so look of the difference,\"\nsaid Mrs.\nForster. The lost of her partly intention of many great could past as his very then worth, were made unavoid of the little partiality,\nan\n--------------\n\nThe best model is found and saved. Current best test loss = 1.289\n","output_type":"stream"}]},{"cell_type":"code","source":"### loading the best model\n\n# reinitialize the model\nbest_model = characterRNN(\n    input_size=vocab_size,\n    embed_size=embed_size,\n    hidden_size=hidden_size,\n    num_layers=num_layers,\n    output_size=vocab_size,\n)\n# load best model's parameters\nbest_model.load_state_dict(torch.load(best_model_filepath))\nbest_model = best_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T13:03:30.309723Z","iopub.execute_input":"2024-04-08T13:03:30.310106Z","iopub.status.idle":"2024-04-08T13:03:30.320968Z","shell.execute_reply.started":"2024-04-08T13:03:30.310075Z","shell.execute_reply":"2024-04-08T13:03:30.320192Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"### generating text with different temperature values \n### (descreasing temperature value provides more flexibility for the next character selection (tends to generate low-quality but more creative texts) and vice versa)\n\n# define possible temperature values\ntemperatures = [1.0, 0.8, 0.5]\n\n# iterate over temperature values\nfor temp in temperatures:\n    # generate text\n    generated_test = generate_text(best_model, generated_text_len=1000, temperature=temp)\n    # display\n    print(f'Temperature = {temp}')\n    print(generated_test)\n    print(\"--------------\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-08T13:03:30.617410Z","iopub.execute_input":"2024-04-08T13:03:30.617768Z","iopub.status.idle":"2024-04-08T13:03:32.007082Z","shell.execute_reply.started":"2024-04-08T13:03:30.617738Z","shell.execute_reply":"2024-04-08T13:03:32.006204Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Temperature = 1.0\n\nonly, which as.\" Miss Bingley. Her Lady Catherine\nand his niece. There is sister that I have all that we may look you, necessanot, she saw. Thought. It told it. Whilley next of summe, she took happiness that she were it was now again as much was being enterledness Sit astonishat\noming\ntrough probably to arved that he would not you case him tilling as to desirit example\nas,\nI wish a desire does pleasure in termities of the estates interest of glander way, convince.--What she deare, with for any deady often; and if could not going much following knew to be ideedial to have knows what I very from thinking one of this favoured to his regard to believe and perfect by elegance had\nbeen one so approaching to see must only are\nsubject, I _mind_ exached on the\nevowly.\"\n\n\"She is not satisf own many in the formpaking did so misuralice to play to her disposition with the\nhouse, as her uncle are, all the whole interest\nother give, by nead very attemon her ainder the same slighted.--Nay, than he les\n--------------\n\n\nTemperature = 0.8\n\nquite intemove me to the girls to think it in enough on the day, which she could have known to think whole proper of the house at\nthe plainly always so mention of mind, on their compliments. Mr. Darcy should never wish the expression to her father to the present of himself in love?--you do be attention of different\nintroduce it would be conversation of so manner with the complain the distress which could\nnot take the considerable must did she acknowledge in thise assured may he will be\nalone at or accusit, and may to wish to what you must be rejection for it.\"\n\n\"Mr. Darcy had leave when all.\"\n\n\"You and the world has obliged to the confidence of it to be manner, however since chose of the evident as happensing sure of something of his side, are their intended therefore, her promople of read that the think who have company had been more carm of with the intimates, and be for all difference in pleasure to a very concern as she\nis these. Elizabeth feather.\n\n\"I do seen you are stund apprope\n--------------\n\n\nTemperature = 0.5\n\n\n     \"Mr. Wickham was a little because it was most account of his endeavour to her handsome was the other\nsoon account of the same surprise what had been some countenance. I cannot be surprised to be a settled to her sisters were about the house of the other feelings and happiness of her father was such a proud, and was such a settled to make to be so little less being one of her considerable the family was to be a settled after a large was the letter and valued me to the day to his\nasure with the particularly eldest as all the evening and consisted again, and who should not dance of the best of the silence of such a great most near her attention of the things to be in the subject of her sister, and made not conceal the stronger of his advantage of her attention of the room of her evening and often and say to him with the less all the conversation was some attentions of the country of the determined to what she was to make her to sit in the particular usual sensible his sister, and sh\n--------------\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}