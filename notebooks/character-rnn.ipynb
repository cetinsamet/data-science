{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\n\nfrom tqdm import tqdm\nimport numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:07:53.984029Z","iopub.execute_input":"2024-04-10T13:07:53.984353Z","iopub.status.idle":"2024-04-10T13:07:57.593755Z","shell.execute_reply.started":"2024-04-10T13:07:53.984328Z","shell.execute_reply":"2024-04-10T13:07:57.592944Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# set seeds for reproducibility\nSEED = 123\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:07:57.595265Z","iopub.execute_input":"2024-04-10T13:07:57.595663Z","iopub.status.idle":"2024-04-10T13:07:57.603264Z","shell.execute_reply.started":"2024-04-10T13:07:57.595630Z","shell.execute_reply":"2024-04-10T13:07:57.602425Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# book collection\nBOOKS = {\n    'TheOdyssey': \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/TheOdyssey_Homer.txt\",\n    'PrideAndPrejudice': \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/PrideAndPrejudice_JaneAusten.txt\",\n    'AJourneyToTheCentreOfTheEarth': \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/JulesVerne_AJourneyToTheCentreOfTheEarth.txt\",\n}\nBOOKS","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:07:57.604374Z","iopub.execute_input":"2024-04-10T13:07:57.604697Z","iopub.status.idle":"2024-04-10T13:07:57.615491Z","shell.execute_reply.started":"2024-04-10T13:07:57.604674Z","shell.execute_reply":"2024-04-10T13:07:57.614643Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'TheOdyssey': 'https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/TheOdyssey_Homer.txt',\n 'PrideAndPrejudice': 'https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/PrideAndPrejudice_JaneAusten.txt',\n 'AJourneyToTheCentreOfTheEarth': 'https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/JulesVerne_AJourneyToTheCentreOfTheEarth.txt'}"},"metadata":{}}]},{"cell_type":"code","source":"# choose a book\nBOOK = 'PrideAndPrejudice'\n\n# get the book's url \nbook_url = BOOKS[BOOK]\n# extract the book's filename from the url\nbook_filename = os.path.basename(book_url) \n\n# download the book in local if it doesn't already exist\nif not os.path.exists(book_filename):\n    try:\n        !wget $book_url\n        print(\"File is succesfully downloaded.\")\n    except Exception as e:\n        print(f\"Could not download the book from {book_url}\")\n        print(e)\nelse:\n    print(\"File has already been downloaded.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:00.189163Z","iopub.execute_input":"2024-04-10T13:08:00.189539Z","iopub.status.idle":"2024-04-10T13:08:01.427231Z","shell.execute_reply.started":"2024-04-10T13:08:00.189510Z","shell.execute_reply":"2024-04-10T13:08:01.425957Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"--2024-04-10 13:08:01--  https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/PrideAndPrejudice_JaneAusten.txt\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 703907 (687K) [text/plain]\nSaving to: 'PrideAndPrejudice_JaneAusten.txt'\n\nPrideAndPrejudice_J 100%[===================>] 687.41K  --.-KB/s    in 0.03s   \n\n2024-04-10 13:08:01 (21.1 MB/s) - 'PrideAndPrejudice_JaneAusten.txt' saved [703907/703907]\n\nFile is succesfully downloaded.\n","output_type":"stream"}]},{"cell_type":"code","source":"# define hyperparameters\nN_EPOCHS = 30\nBATCH_SIZE = 128\nSEQ_LEN = 200\nLEARNING_RATE = 1e-4\nEMBED_SIZE = 100\nHIDDEN_SIZE = 100\nNUM_LAYERS = 1\nTEST_SIZE = 0.2\nEARLY_STOPPING_STEP_SIZE = 5\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nBEST_MODEL_FILEPATH = 'best_model.pt'\n\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:08.905807Z","iopub.execute_input":"2024-04-10T13:08:08.906203Z","iopub.status.idle":"2024-04-10T13:08:08.941836Z","shell.execute_reply.started":"2024-04-10T13:08:08.906152Z","shell.execute_reply":"2024-04-10T13:08:08.940933Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"def load_text(fp):\n    with open(fp, mode='r') as infile:\n        text = ''.join([row for row in infile])\n    return text\n\n# load text\ntext = load_text(book_filename)\n\n# Get the number of characters in the text\ntext_len = len(text)\nprint(f'Number of characters in the text = {text_len}')\nprint(\"--------------\\n\")\n\n# Print a sample from the text\nidx = np.random.randint(low=0, high=text_len-SEQ_LEN)\nprint(f'Sample text:\\n{text[idx:(idx + SEQ_LEN)]}')\nprint(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:15.548558Z","iopub.execute_input":"2024-04-10T13:08:15.548935Z","iopub.status.idle":"2024-04-10T13:08:15.562298Z","shell.execute_reply.started":"2024-04-10T13:08:15.548904Z","shell.execute_reply":"2024-04-10T13:08:15.561188Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Number of characters in the text = 690654\n--------------\n\nSample text:\n it\nwas all done very well. She had also to anticipate how her visit would\npass, the quiet tenor of their usual employments, the vexatious\ninterruptions of Mr. Collins, and the gaieties of their inter\n--------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# define vocabulary (set of unique characters in the source text)\nvocab = sorted(list(set(text)))\n# get the vocabulary size\nvocab_size = len(vocab)\n\n# print vocabulary as a single string \nprint(f\"Vocabulary: {''.join(vocab)}\")\nprint(f\"Vocabulary size = {vocab_size}\")\nprint(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:23.862159Z","iopub.execute_input":"2024-04-10T13:08:23.862628Z","iopub.status.idle":"2024-04-10T13:08:23.877578Z","shell.execute_reply.started":"2024-04-10T13:08:23.862596Z","shell.execute_reply":"2024-04-10T13:08:23.876668Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Vocabulary: \n !\"&'()*,-.1234568:;?ABCDEFGHIJKLMNOPRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyzàê\nVocabulary size = 78\n--------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# define the mappings (as dictionary) of \n# 'a character (from the vocab) to a unique ID' ---> 'char2int'\n# and\n# 'a unique ID to a character (from the vocab)'  ---> 'int2char'\nchar2int = {c: idx for idx, c in enumerate(vocab)}\nint2char = {idx: c for idx, c in enumerate(vocab)}\n\n# define the encode() that encodes/converts a character to a unique ID \ndef encode(character):\n    global char2int\n    return char2int[character]\n\n# define the encode() that decodes/converts back a unique ID to a character\ndef decode(integer):\n    global int2char\n    return int2char[integer]\n\n# print an example of how encode() and decode() operate\nchar = 'A'\nprint(f\"char '{char}' | encode('{char}') = {encode(char)}\")\nprint(f\"char '{char}' | decode(encode('{char}')) = {decode(encode(char))}\")\nprint(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:30.487047Z","iopub.execute_input":"2024-04-10T13:08:30.487923Z","iopub.status.idle":"2024-04-10T13:08:30.494820Z","shell.execute_reply.started":"2024-04-10T13:08:30.487895Z","shell.execute_reply":"2024-04-10T13:08:30.493835Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"char 'A' | encode('A') = 22\nchar 'A' | decode(encode('A')) = A\n--------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# define the TextDataset as an instance of torch.nn.Dataset\nclass TextDataset(Dataset):\n    def __init__(self, text, seq_len):\n        super().__init__()\n        self.text = text\n        self.seq_len = seq_len\n\n    def __len__(self):\n        # define the number of samples in the dataset\n        return len(self.text) - self.seq_len - 1\n\n    def __getitem__(self, idx):\n        # x = [c0, c1, ... cN]\n        x = torch.tensor(\n            [encode(char) for char in self.text[idx:(idx + self.seq_len)]], \n            dtype=torch.long\n        )\n        # y = [c1, c1, ... c(N+1)]\n        y = torch.tensor(\n            [encode(char) for char in self.text[(idx + 1):(idx + 1 + self.seq_len)]], \n            dtype=torch.long\n        )\n        return x, y","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:35.710973Z","iopub.execute_input":"2024-04-10T13:08:35.711325Z","iopub.status.idle":"2024-04-10T13:08:35.718590Z","shell.execute_reply.started":"2024-04-10T13:08:35.711296Z","shell.execute_reply":"2024-04-10T13:08:35.717648Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# define the train and test data\ntrain_data = text[:-(int(text_len * TEST_SIZE))]\ntest_data = text[-(int(text_len * TEST_SIZE)):]\n\n# print the length of train and test data\nprint(f'Length of the train text = {len(train_data)}')\nprint(f'Length of the test text  = {len(test_data)}')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:43.199842Z","iopub.execute_input":"2024-04-10T13:08:43.200537Z","iopub.status.idle":"2024-04-10T13:08:43.206676Z","shell.execute_reply.started":"2024-04-10T13:08:43.200504Z","shell.execute_reply":"2024-04-10T13:08:43.205721Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Length of the train text = 552524\nLength of the test text  = 138130\n","output_type":"stream"}]},{"cell_type":"code","source":"# initialize train and test datasets\ntrain_dset = TextDataset(train_data, SEQ_LEN)\ntest_dset = TextDataset(test_data, SEQ_LEN)\n\n# initialize train and test iterators\ntrain_iterator = DataLoader(train_dset, BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\ntest_iterator = DataLoader(test_dset, BATCH_SIZE, shuffle=False, pin_memory=True)  # no need to shuffle the test dset","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:48.067426Z","iopub.execute_input":"2024-04-10T13:08:48.067770Z","iopub.status.idle":"2024-04-10T13:08:48.073530Z","shell.execute_reply.started":"2024-04-10T13:08:48.067744Z","shell.execute_reply":"2024-04-10T13:08:48.072447Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# define characterRNN module\nclass characterRNN(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers, output_size):\n        super().__init__()  \n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n\n        self.embedding_layer = nn.Embedding(input_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden_state, cell_state):\n        x = self.embedding_layer(x)\n        x, (hidden_state, cell_state) = self.lstm(x, (hidden_state, cell_state))\n        x = self.fc(x)\n        return x, hidden_state, cell_state\n    \n    def init_hidden_and_cell(self, batch_size):\n        size = (self.num_layers, batch_size, self.hidden_size)\n        hidden_state, cell_state = torch.zeros(size, dtype=torch.float), torch.zeros(size, dtype=torch.float)\n        return hidden_state, cell_state","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:52.713392Z","iopub.execute_input":"2024-04-10T13:08:52.714222Z","iopub.status.idle":"2024-04-10T13:08:52.722566Z","shell.execute_reply.started":"2024-04-10T13:08:52.714189Z","shell.execute_reply":"2024-04-10T13:08:52.721548Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def generate_text(model, start_char='\\n', generated_text_len=250, temperature=1.0):\n    # global variables\n    global DEVICE\n    # set model to eval mode\n    model.eval()\n    \n    # add the start character at the beginning of the generated text sequence\n    generated_text = start_char\n    \n    # operate under inference mode to avoid gradient computations and speed up the process\n    with torch.inference_mode():\n        # set the initial hidden and cell state tensors for LSTM training\n        hidden_state, cell_state = model.init_hidden_and_cell(batch_size=1)\n        hidden_state, cell_state = hidden_state.to(DEVICE), cell_state.to(DEVICE)\n        \n        # encode the start_char and add a single batch dimensionality \n        x = torch.tensor(encode(start_char), dtype=torch.long).view(1, -1).to(DEVICE)\n        \n        # generate N characters, where N = generated_text_len\n        for _ in range(generated_text_len):\n            # predict the probabilities of the next character\n            y, hidden_state, cell_state = model(x, hidden_state, cell_state)\n            # select the next character from a multinomial distribution\n            ### (decreasing temperature value tends to generate more boring and predictable texts while increasing it brings more creativity and possibly lower quality texts)\n            x = torch.multinomial(y[0].div(temperature).exp(), num_samples=1)            \n            # decode the next character (for human readibility) \n            next_char = decode(x.item())\n            # add next character to the end of the generated text\n            generated_text += next_char\n\n    return generated_text","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:08:57.944661Z","iopub.execute_input":"2024-04-10T13:08:57.945002Z","iopub.status.idle":"2024-04-10T13:08:57.953359Z","shell.execute_reply.started":"2024-04-10T13:08:57.944976Z","shell.execute_reply":"2024-04-10T13:08:57.952365Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator):\n    # global variables\n    global DEVICE\n    # set model to eval mode\n    model.eval()\n    \n    # operate under inference mode to avoid gradient computations and speed up the process\n    with torch.inference_mode():\n        # initialize loss\n        loss_sum = 0.0\n        \n        # iterate over batches\n        for x, y in tqdm(iterator):\n            # carry tensors to available device\n            x, y = x.to(DEVICE), y.to(DEVICE)\n\n            # set the initial hidden and cell state tensors for LSTM training\n            batch_size = len(x)  # get the current batch_size\n            hidden_state, cell_state = model.init_hidden_and_cell(batch_size)\n            hidden_state, cell_state = hidden_state.to(DEVICE), cell_state.to(DEVICE)\n\n            # forward pass (get logits, hidden and cell states for each characters in the sequence)\n            logits, hidden_state, cell_state = model(x, hidden_state, cell_state)\n\n            # compute loss\n            B, S, C = logits.shape  # B: batch size, S: seq length, C: channnel (or embed) size\n            loss = F.cross_entropy(logits.view(B*S, C), y.view(-1))\n            \n            # add batch loss to total loss sum\n            loss_sum += loss.item()\n    \n    # compute avg loss\n    loss_avg = loss_sum / len(iterator)\n    return loss_avg","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:09:04.545191Z","iopub.execute_input":"2024-04-10T13:09:04.545561Z","iopub.status.idle":"2024-04-10T13:09:04.553319Z","shell.execute_reply.started":"2024-04-10T13:09:04.545530Z","shell.execute_reply":"2024-04-10T13:09:04.552436Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# initialize characterRNN model\nmodel = characterRNN(\n    input_size=vocab_size,\n    embed_size=EMBED_SIZE,\n    hidden_size=HIDDEN_SIZE,\n    num_layers=NUM_LAYERS,\n    output_size=vocab_size,\n).to(DEVICE)\n\n# initialize the optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# init the best test loss as positive inifinity\nbest_test_loss = float('inf')\n\n# initialize a counter for early stopping\nbest_streak_count = 0\n\n###### training loop ######\n# iterate over epochs\nfor epoch_idx in range(1, N_EPOCHS+1):\n    # set model to train mode\n    model.train()  \n    # initialize train loss\n    loss_train = 0.0\n\n    # iterate over batches        \n    for iter_idx, (x, y) in tqdm(enumerate(train_iterator), total=len(train_iterator)):  \n        # carry tensors to available device\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        \n        # set the initial hidden and cell state tensors for LSTM training\n        hidden_state, cell_state = model.init_hidden_and_cell(BATCH_SIZE)\n        hidden_state, cell_state = hidden_state.to(DEVICE), cell_state.to(DEVICE)\n                \n        # forward pass (get logits, hidden and cell states for each characters in the sequence)\n        logits, hidden_state, cell_state = model(x, hidden_state, cell_state)\n        \n        # compute loss\n        B, S, C = logits.shape  # B: batch size, S: seq length, C: channnel (or embedding) size\n        loss = F.cross_entropy(logits.view(B*S, C), y.view(-1))\n        \n        # update gradients\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # add batch loss to total loss sum\n        loss_train += loss.item()\n        \n    # print epoch logs\n    loss_train /= len(train_iterator)\n    loss_test = evaluate(model, test_iterator)\n    print(f\"epoch {epoch_idx:02} || train loss = {loss_train:.3f}\\ttest loss = {loss_test:.3f}\", end='\\n\\n')\n    \n    # save the current model as the best model if the current test loss is the least achieved \n    if loss_test < best_test_loss:\n        # save the curent model's parameters as the best model parameters\n        torch.save(model.state_dict(), BEST_MODEL_FILEPATH)\n        # replace the best test loss with the current best loss\n        best_test_loss = loss_test\n        # reset early stoppping counter \n        best_streak_count = 0\n        # display info\n        print(f'The best model is found and saved. Current best test loss = {best_test_loss:.3f}')\n        # generate a text and display\n        print(\"--------------\")\n        print(f\"GENERATED TEXT:{generate_text(model, generated_text_len=250)}\")\n    else:\n        # update early stoppping counter \n        best_streak_count += 1\n\n    # check early stopping condition\n    if best_streak_count == EARLY_STOPPING_STEP_SIZE:\n        print(f\"A better model has not been found in the last {EARLY_STOPPING_STEP_SIZE} epochs. Early stopping...\")\n        break\n        \n    print(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:09:11.006057Z","iopub.execute_input":"2024-04-10T13:09:11.006441Z","iopub.status.idle":"2024-04-10T14:04:41.506607Z","shell.execute_reply.started":"2024-04-10T13:09:11.006412Z","shell.execute_reply":"2024-04-10T14:04:41.505583Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.82it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 01 || train loss = 2.191\ttest loss = 1.731\n\nThe best model is found and saved. Current best test loss = 1.731\n--------------\nGENERATED TEXT:\n dfy formred Pece frotur enterpxiafiage in this genk\"\n a bying6 her parly terhard as friwe for courcut povay it seepe veray ofor uncosted be inded, a consusatbent is kinxidention, she the not am that be hit the\nown the mishions,\" now poicweld not bee\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:20<00:00, 30.79it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 02 || train loss = 1.566\ttest loss = 1.482\n\nThe best model is found and saved. Current best test loss = 1.482\n--------------\nGENERATED TEXT:\n\n\"Caus Mr. My was her feltation muty. My sade awe rading certon.\nAnd\naboy Eliza'Ds. Haptly blatt poces, and awast before his prelits. I shanded the tole we could sowr.\nMaribet, and, that you as tendist you for what amosighted porton; and becaalfied D\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.83it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 03 || train loss = 1.403\ttest loss = 1.393\n\nThe best model is found and saved. Current best test loss = 1.393\n--------------\nGENERATED TEXT:\nthough she implaisue?\" repried it that be reaidely in is no of Mr. Bingley rition yis _make is the place to think you advances coplie mights. Colfelless their even in his time Mrs. Collins, there frieved young aways he mefut Miss Bingley means persua\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 31.03it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 04 || train loss = 1.329\ttest loss = 1.350\n\nThe best model is found and saved. Current best test loss = 1.350\n--------------\nGENERATED TEXT:\n\n\"After divession of something out sore. Mr. Darcy little they when Longbongestle found to sat me high illy,\" said Elizabeeth's nature out. Do yen had been disennetish herself, and ffather better's pleased? I have\nno rirlieve Netherfied to the might \n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.92it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 05 || train loss = 1.286\ttest loss = 1.325\n\nThe best model is found and saved. Current best test loss = 1.325\n--------------\nGENERATED TEXT:\n\"To left the gentlence of the sured on\nwhich\nSir William in it. Every toon my\namingation lift. The resolving, while he was\n.\"\n\"I cannovect of the subject;. were alone, with your leave to my abse in the engagement. He was\nof seeliss on it about hanced\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.87it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 41.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 06 || train loss = 1.256\ttest loss = 1.308\n\nThe best model is found and saved. Current best test loss = 1.308\n--------------\nGENERATED TEXT:\nexpectal a moment, by it\narresting any that Wickham propufe to reeboring impareshonouration as young munced no ill visit to know however, had settl; but\nher wask turned to give her, carfually dounty.\n\nAne not be visithy hoods woman in quittain she se\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.84it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 41.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 07 || train loss = 1.233\ttest loss = 1.296\n\nThe best model is found and saved. Current best test loss = 1.296\n--------------\nGENERATED TEXT:\n     in his reflected a said, and a sort, was sister might have never been going him was been\nmanner was\nentaim?\nAnd when she\nbusiness of beingsfordshire was an exaction of the thought perfectly provacomes uneasy, he verised Kent for your ratement wh\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.82it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 08 || train loss = 1.216\ttest loss = 1.288\n\nThe best model is found and saved. Current best test loss = 1.288\n--------------\nGENERATED TEXT:\n     any face of\nhis faithship's daughter, I do not know, before I am supprriently\ntoo humbles.\"\n \n\n       *\n  *    *         wou entreagery tonally\napolunt, delighted.\n\nButs,\nin the good yest treated, andactio, a laious to judge in the head to Mary \n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:20<00:00, 30.78it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 09 || train loss = 1.202\ttest loss = 1.282\n\nThe best model is found and saved. Current best test loss = 1.282\n--------------\nGENERATED TEXT:\nDenny Jane was\n     mother attended to\na much connection. She does, walk it. To vexations. I shall\nbe, propsed by under you were not head me. In more than her uswelly annot his father by thew hardless by the care, Jane as idea in welant sharedly seen\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.98it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 41.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 10 || train loss = 1.190\ttest loss = 1.278\n\nThe best model is found and saved. Current best test loss = 1.278\n--------------\nGENERATED TEXT:\n     princing schies were daughters was a short enjoyment, and relate no\nmealy\nbetween they mode previded sisters. His\nopening.\n\nMrs. Long had been more by the\npresent came his hand it\nis describlibareshippenectly at an beharly in from his discrodure\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 31.02it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 11 || train loss = 1.180\ttest loss = 1.275\n\nThe best model is found and saved. Current best test loss = 1.275\n--------------\nGENERATED TEXT:\nwas\nmuch\n     flent which I conselievine that the tifferuded her,\nshe had been eefficient woman a longed, with gratumes them;\nthan her hand Mr. Bingley within\nthe pausitness\nof conviction in London, indely.\n\n\"You know him without thising them that th\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:22<00:00, 30.33it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 12 || train loss = 1.171\ttest loss = 1.273\n\nThe best model is found and saved. Current best test loss = 1.273\n--------------\nGENERATED TEXT:\nDOarcy chose presertingly was nobody from a content, Mr. Darcy with a moment. Lady Catherine, and yessman is musif Prass of seconned to be-belicaking his sideful place now, the very farthew on every howlege, for the time\nof Miss Lucas,\" conon the mos\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:20<00:00, 30.68it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 41.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 13 || train loss = 1.164\ttest loss = 1.271\n\nThe best model is found and saved. Current best test loss = 1.271\n--------------\nGENERATED TEXT:\n\nand her resentment, to have Macy was dinner had been, and give left every and often, and at little by yourself, who, and was desaid Wickham!--anstance was to making her sister remains!\"\n\n\"She is still beauty.\"\n\n\"Could be hapbouth ove, really ask, an\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 31.00it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 14 || train loss = 1.157\ttest loss = 1.271\n\nThe best model is found and saved. Current best test loss = 1.271\n--------------\nGENERATED TEXT:\nher guility, how had rather disally\n     but even herself, he is to be breakfast carried of the surcits of\nthe young lady and nor that last taken, his incliable; it gave her an absence observed young.--But were as Miss Lucas and Mr. Bennet, \"Such as\n\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:18<00:00, 31.05it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 15 || train loss = 1.151\ttest loss = 1.270\n\nThe best model is found and saved. Current best test loss = 1.270\n--------------\nGENERATED TEXT:\nwat\nmorning it!\"\n\n\"And he asked yourself, and, or a friend.--He be was entering whether they bring in a home into ourselves from me appear Jane, my concern of procied, at at allowable to the care of his encoarmonts and herself that _I_ have the slace\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.93it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 16 || train loss = 1.145\ttest loss = 1.271\n\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.91it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 17 || train loss = 1.140\ttest loss = 1.271\n\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:19<00:00, 30.95it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 18 || train loss = 1.135\ttest loss = 1.272\n\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:20<00:00, 30.82it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 41.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch 19 || train loss = 1.131\ttest loss = 1.273\n\n--------------\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4315/4315 [02:20<00:00, 30.74it/s]\n100%|██████████| 1078/1078 [00:26<00:00, 40.32it/s]","output_type":"stream"},{"name":"stdout","text":"epoch 20 || train loss = 1.127\ttest loss = 1.274\n\nA better model has not been found in the last 5 epochs. Early stopping...\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"### loading the best model\n\n# reinitialize the model\nbest_model = characterRNN(\n    input_size=vocab_size,\n    embed_size=EMBED_SIZE,\n    hidden_size=HIDDEN_SIZE,\n    num_layers=NUM_LAYERS,\n    output_size=vocab_size,\n)\n# load best model's parameters\nbest_model.load_state_dict(torch.load(BEST_MODEL_FILEPATH))\nbest_model = best_model.to(DEVICE)\nprint(\"Model is initialized and the best model parameters are loaded.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T14:04:53.745851Z","iopub.execute_input":"2024-04-10T14:04:53.746217Z","iopub.status.idle":"2024-04-10T14:04:53.757911Z","shell.execute_reply.started":"2024-04-10T14:04:53.746186Z","shell.execute_reply":"2024-04-10T14:04:53.756920Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model is initialized and the best model parameters are loaded.\n","output_type":"stream"}]},{"cell_type":"code","source":"### generating text and experimenting with different temperature values \n### (decreasing temperature value tends to generate more boring and predictable texts while increasing it brings more creativity and possibly lower quality texts)\n\n# define possible temperature values\ntemperatures = [0.25, 0.5, 1.0]\ngenerated_text_len = 1000\n\n# iterate over temperature values\nfor temp in temperatures:\n    # generate text\n    generated_text = generate_text(best_model, generated_text_len=generated_text_len, temperature=temp)\n    # display\n    print(f'Temperature = {temp}')\n    print(generated_text)\n    print(\"--------------\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T14:06:10.019774Z","iopub.execute_input":"2024-04-10T14:06:10.020501Z","iopub.status.idle":"2024-04-10T14:06:11.420311Z","shell.execute_reply.started":"2024-04-10T14:06:10.020467Z","shell.execute_reply":"2024-04-10T14:06:11.419364Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Temperature = 0.25\n\n     the other friends and a most attention of the considerable to be all that he had not the letter, and they were at the same particular could not be such a settled to the subject of the family as the proper of the same present of his family and some promised to the party. When they were an actively the concern in the subject of the particular of the rest of the family and to the present at the subject of the particulars of his sister and the manner of her attention of the subjects were some of the soon attention was all the subject of her father and happiness to any other feelings and a silence of the other particular for endeavour to the particular of the next morning to the construed to her than to be all the subject of the particulars of the morning was the present of the company of her attention of his sister to the particulars of the same promised to her house to be a few moments were at the subject of the present away to the probably and the house, and the considerable to the \n--------------\n\n\nTemperature = 0.5\n\n     \"I am sure you do not think it was all the sense of his sister to his house and recollections which\nhad allowed her was so much as she was all the sort of any thing that you are not a man, the more to see her should not a welf the last officers, and so much to the subject of the meeting and to be a reserved to see you are not all the information of the particular cousin will not be all this study you are the ladies was too much little disposition as she would not be of a sex. They has been my general very ladies of his own cousin she was every imprudent to give any of the sort of the next morning, Elizabeth and her family as much at Netherfield before, and as I wish her wife to be so much explain to any of the first engaged on the continued there was not any thing to the so much of the world himself, and soon at line, and the left the studies of her family to a stay long to the letter from\nmeaning last observing and accepted to her particular of the following every conversation wi\n--------------\n\n\nTemperature = 1.0\n\nand hen, the chance of the world, and an eagerness liked your fancy, however, there will be\nresolving his any bady continued before the shame. You must be any town are grateful to be pleasantly in Meryton old. She was; and though were\nelibed meritterns, I am to never be elegant to appear along the period of Mr. and Miss Bingley\navoid alreable.\"\n\n\"Not, if Collined little of\nclam, he could be a suchanched been to the concerns will not help we had her\nacquainting and only sinceroush had thing of though she must know look me?\"\n\n\"Yes, and, and who was entravaching the kindness of ten condestice, and said without the wates to firish humarter.\n\nHis poor than ten firsticature settled in ever day to marry.\n\n\"Oh, Nether tolling their qualified; and\nher immediate unhis aston, and Mr. Darcy increases half in an hour yeather. Jane were at Brighton, and ready to see for not two riverected\nwroth another never be part of Longbouth the little\nforward to those than Jane, wold the seations,\n\n\"I kelinatio\n--------------\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}