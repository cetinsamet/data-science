{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b4e636d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-11T08:17:47.702151Z",
     "iopub.status.busy": "2024-04-11T08:17:47.701460Z",
     "iopub.status.idle": "2024-04-11T08:17:51.228443Z",
     "shell.execute_reply": "2024-04-11T08:17:51.227671Z"
    },
    "papermill": {
     "duration": 3.537948,
     "end_time": "2024-04-11T08:17:51.230698",
     "exception": false,
     "start_time": "2024-04-11T08:17:47.692750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d05e03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:17:51.245607Z",
     "iopub.status.busy": "2024-04-11T08:17:51.245181Z",
     "iopub.status.idle": "2024-04-11T08:17:51.252954Z",
     "shell.execute_reply": "2024-04-11T08:17:51.252196Z"
    },
    "papermill": {
     "duration": 0.017399,
     "end_time": "2024-04-11T08:17:51.254970",
     "exception": false,
     "start_time": "2024-04-11T08:17:51.237571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set seeds for reproducibility\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8123da26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:17:51.270040Z",
     "iopub.status.busy": "2024-04-11T08:17:51.269422Z",
     "iopub.status.idle": "2024-04-11T08:17:53.299477Z",
     "shell.execute_reply": "2024-04-11T08:17:53.298045Z"
    },
    "papermill": {
     "duration": 2.03989,
     "end_time": "2024-04-11T08:17:53.301618",
     "exception": false,
     "start_time": "2024-04-11T08:17:51.261728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-11 08:17:52--  https://raw.githubusercontent.com/cetinsamet/data-science/main/data/translation/EN2TR.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 33268135 (32M) [text/plain]\r\n",
      "Saving to: 'EN2TR.txt'\r\n",
      "\r\n",
      "EN2TR.txt           100%[===================>]  31.73M   198MB/s    in 0.2s    \r\n",
      "\r\n",
      "2024-04-11 08:17:53 (198 MB/s) - 'EN2TR.txt' saved [33268135/33268135]\r\n",
      "\r\n",
      "File is succesfully downloaded.\n"
     ]
    }
   ],
   "source": [
    "# set URL to download data\n",
    "translation_data_url = \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/translation/EN2TR.txt\"\n",
    "# get data filename\n",
    "translation_data_filename = os.path.basename(translation_data_url)\n",
    "\n",
    "# download the data in local if it doesn't already exist\n",
    "if not os.path.exists(translation_data_filename):\n",
    "    try:\n",
    "        !wget $translation_data_url\n",
    "        print(\"File is succesfully downloaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download the book from {translation_data_url}\")\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"File has already been downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af5aafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:17:53.317186Z",
     "iopub.status.busy": "2024-04-11T08:17:53.316884Z",
     "iopub.status.idle": "2024-04-11T08:17:53.382787Z",
     "shell.execute_reply": "2024-04-11T08:17:53.381894Z"
    },
    "papermill": {
     "duration": 0.075767,
     "end_time": "2024-04-11T08:17:53.384703",
     "exception": false,
     "start_time": "2024-04-11T08:17:53.308936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "N_EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "EMBED_SIZE = 256\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 1\n",
    "TEST_SIZE = 0.2\n",
    "SAMPLE_RATIO = 1.0\n",
    "EARLY_STOPPING_STEP_SIZE = 5\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BEST_ENCODER_FILEPATH = 'best_encoder.pt'\n",
    "BEST_DECODER_FILEPATH = 'best_decoder.pt'\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838c735a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:17:53.399528Z",
     "iopub.status.busy": "2024-04-11T08:17:53.399256Z",
     "iopub.status.idle": "2024-04-11T08:17:53.405580Z",
     "shell.execute_reply": "2024-04-11T08:17:53.404774Z"
    },
    "papermill": {
     "duration": 0.016234,
     "end_time": "2024-04-11T08:17:53.407775",
     "exception": false,
     "start_time": "2024-04-11T08:17:53.391541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(fp, sep='\\t', remove_last_char=False, drop_first=False):\n",
    "    with open(fp, mode='r') as infile:\n",
    "        sentences = [row.strip().split(sep) for idx, row in enumerate(infile)]\n",
    "        if drop_first:\n",
    "            sentences = sentences[1:]\n",
    "    sentences_src, sentences_tgt = zip(*sentences)\n",
    "    if remove_last_char:\n",
    "        sentences_src = [sentence[:-1] for sentence in sentences_src]\n",
    "        sentences_tgt = [sentence[:-1] for sentence in sentences_tgt]\n",
    "    return sentences_src, sentences_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66f4814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:17:53.423336Z",
     "iopub.status.busy": "2024-04-11T08:17:53.423090Z",
     "iopub.status.idle": "2024-04-11T08:17:55.316144Z",
     "shell.execute_reply": "2024-04-11T08:17:55.315209Z"
    },
    "papermill": {
     "duration": 1.903795,
     "end_time": "2024-04-11T08:17:55.318442",
     "exception": false,
     "start_time": "2024-04-11T08:17:53.414647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 473035 in total\n",
      "There are 473035 in total after sampling %100.0 of all sentences\n",
      "\n",
      "Examples:\n",
      "Tom is in jail, awaiting trial <---> Tom duruşmayı beklerken hapistedir\n",
      "I've got no quarrel with you two <---> Siz ikinizle sorunum yok\n",
      "Are you busy here <---> Burada meşgul müsün\n",
      "Tom felt better <---> Tom daha iyi hissetti\n",
      "Tom didn't bother to answer <---> Tom cevap verme zahmetine girmedi\n"
     ]
    }
   ],
   "source": [
    "# load all sentences for both source and target languages\n",
    "all_sentences_src, all_sentences_tgt = load_data(translation_data_filename, remove_last_char=True)\n",
    "assert len(all_sentences_src) == len(all_sentences_tgt)  # sanity check\n",
    "\n",
    "# get the number of all sentences\n",
    "n_all_sentences = len(all_sentences_src)\n",
    "print(f\"There are {n_all_sentences} in total\")\n",
    "\n",
    "### sample sentences with a SAMPLE_RATIO to get a portion to use in training\n",
    "# get the number of (sampled) sentences\n",
    "n_sentences = int(n_all_sentences * SAMPLE_RATIO)\n",
    "# get the sampled source and target sentences\n",
    "sentences_src, sentences_tgt = all_sentences_src[:n_sentences], all_sentences_tgt[:n_sentences]\n",
    "print(f\"There are {n_sentences} in total after sampling %{SAMPLE_RATIO*100} of all sentences\")\n",
    "\n",
    "# display some example translation from the data\n",
    "print('\\nExamples:')\n",
    "for idx in np.random.randint(low=0, high=n_sentences, size=5):\n",
    "    print(f\"{sentences_src[idx]} <---> {sentences_tgt[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b86d0c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:17:55.334232Z",
     "iopub.status.busy": "2024-04-11T08:17:55.333924Z",
     "iopub.status.idle": "2024-04-11T08:18:19.007787Z",
     "shell.execute_reply": "2024-04-11T08:18:19.006781Z"
    },
    "papermill": {
     "duration": 23.685424,
     "end_time": "2024-04-11T08:18:19.011197",
     "exception": false,
     "start_time": "2024-04-11T08:17:55.325773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473035/473035 [00:23<00:00, 20021.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There 387162 sentences in train data.\n",
      "There 85873 sentences in test data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### split sentences into train and test sets\n",
    "# set the number of test sentences\n",
    "n_test = int(n_sentences * TEST_SIZE)\n",
    "# randomly select test sentence indices\n",
    "test_indices = np.random.randint(low=0, high=n_sentences, size=n_test)\n",
    "\n",
    "# split sentences into train and test, source and target language sets\n",
    "train_data_src, train_data_tgt = [], []\n",
    "test_data_src, test_data_tgt = [], []\n",
    "for i in tqdm(range(n_sentences)):\n",
    "    if i in test_indices:\n",
    "        test_data_src.append(sentences_src[i])\n",
    "        test_data_tgt.append(sentences_tgt[i])\n",
    "    else:\n",
    "        train_data_src.append(sentences_src[i])\n",
    "        train_data_tgt.append(sentences_tgt[i])\n",
    "\n",
    "# get the number of train sentences\n",
    "n_train = len(train_data_src)\n",
    "print(f\"There {n_train} sentences in train data.\")\n",
    "\n",
    "# get the number test train sentences\n",
    "n_test = len(test_data_src)\n",
    "print(f\"There {n_test} sentences in test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28a3a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:19.067787Z",
     "iopub.status.busy": "2024-04-11T08:18:19.067449Z",
     "iopub.status.idle": "2024-04-11T08:18:19.072029Z",
     "shell.execute_reply": "2024-04-11T08:18:19.071265Z"
    },
    "papermill": {
     "duration": 0.033453,
     "end_time": "2024-04-11T08:18:19.073995",
     "exception": false,
     "start_time": "2024-04-11T08:18:19.040542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define function to tokenize sentences (in a very simple way)\n",
    "def tokenize(sentences):\n",
    "    return [el for sentence in sentences for el in sentence.lower().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e37fe140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:19.127606Z",
     "iopub.status.busy": "2024-04-11T08:18:19.127320Z",
     "iopub.status.idle": "2024-04-11T08:18:20.925427Z",
     "shell.execute_reply": "2024-04-11T08:18:20.923950Z"
    },
    "papermill": {
     "duration": 1.828464,
     "end_time": "2024-04-11T08:18:20.928784",
     "exception": false,
     "start_time": "2024-04-11T08:18:19.100320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (SRC) size = 27504\n",
      "Vocabulary (TGT) size = 102201\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define special tokens (we won't use <UNK> but it's a good practise to have it)\n",
    "special_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "\n",
    "# define source and target language vocabularies by tokenizing sentences\n",
    "# (and add special tokens to both vocabularys)\n",
    "vocab_src = special_tokens + sorted(list(set(tokenize(sentences_src))))\n",
    "vocab_tgt = special_tokens + sorted(list(set(tokenize(sentences_tgt))))\n",
    "\n",
    "# get the source and target languages' vocabulary sizes\n",
    "vocab_src_size = len(vocab_src)\n",
    "vocab_tgt_size = len(vocab_tgt)\n",
    "\n",
    "print(f\"Vocabulary (SRC) size = {vocab_src_size}\")\n",
    "print(f\"Vocabulary (TGT) size = {vocab_tgt_size}\")\n",
    "print(\"--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b496255a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:20.992947Z",
     "iopub.status.busy": "2024-04-11T08:18:20.992165Z",
     "iopub.status.idle": "2024-04-11T08:18:21.085378Z",
     "shell.execute_reply": "2024-04-11T08:18:21.084389Z"
    },
    "papermill": {
     "duration": 0.12698,
     "end_time": "2024-04-11T08:18:21.088179",
     "exception": false,
     "start_time": "2024-04-11T08:18:20.961199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'What time is it?' is encoded as [26794, 24744, 13314, 13349].\n",
      "'[26794, 24744, 13314, 13349]' is encoded as 'what time is it?'.\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the mappings (as dictionary) of \n",
    "# 'a token (from the vocab) to a unique ID' ---> 'char2int'\n",
    "# and\n",
    "# 'a unique ID to a token (from the vocab)'  ---> 'int2char'\n",
    "# for both source and target languages\n",
    "char2int_src = {c: idx for idx, c in enumerate(vocab_src)}\n",
    "int2char_src = {idx: c for idx, c in enumerate(vocab_src)}\n",
    "\n",
    "char2int_tgt = {c: idx for idx, c in enumerate(vocab_tgt)}\n",
    "int2char_tgt = {idx: c for idx, c in enumerate(vocab_tgt)}\n",
    "\n",
    "# define the encode() that encodes/converts a token to a unique ID \n",
    "def encode(character, char2int):\n",
    "    return char2int[character]\n",
    "\n",
    "# define the encode() that decodes/converts back a unique ID to a token\n",
    "def decode(integer, int2char):\n",
    "    return int2char[integer]\n",
    "\n",
    "# show an example of how encode() and decode() operate\n",
    "sentence_src = 'What time is it?'\n",
    "sentence_src_encoded = [encode(token, char2int_src) for token in tokenize([sentence_src])]\n",
    "print(f\"'{sentence_src}' is encoded as {sentence_src_encoded}.\")\n",
    "\n",
    "sentence_src_encoded_decoded = [decode(token, int2char_src) for token in sentence_src_encoded]\n",
    "print(f\"'{sentence_src_encoded}' is encoded as '{' '.join(sentence_src_encoded_decoded)}'.\")\n",
    "print(\"--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e92e214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:21.150559Z",
     "iopub.status.busy": "2024-04-11T08:18:21.149739Z",
     "iopub.status.idle": "2024-04-11T08:18:21.159700Z",
     "shell.execute_reply": "2024-04-11T08:18:21.158776Z"
    },
    "papermill": {
     "duration": 0.042627,
     "end_time": "2024-04-11T08:18:21.161911",
     "exception": false,
     "start_time": "2024-04-11T08:18:21.119284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the LanguageDataset as an instance of torch.nn.Dataset\n",
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, sentences_src, sentences_tgt, vocab_src, vocab_tgt):\n",
    "        super().__init__()\n",
    "        self.sentences_src = sentences_src\n",
    "        self.sentences_tgt = sentences_tgt\n",
    "        self.vocab_src = vocab_src\n",
    "        self.vocab_tgt = vocab_tgt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences_src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_src = torch.tensor(\n",
    "            [encode(token, char2int_src) for token in tokenize([self.sentences_src[idx]])], \n",
    "            dtype=torch.long\n",
    "        )\n",
    "        x_tgt = torch.tensor(\n",
    "            [encode(token, char2int_tgt) for token in tokenize([self.sentences_tgt[idx]])],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        return x_src, x_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a82e4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:21.218501Z",
     "iopub.status.busy": "2024-04-11T08:18:21.217738Z",
     "iopub.status.idle": "2024-04-11T08:18:21.228891Z",
     "shell.execute_reply": "2024-04-11T08:18:21.227947Z"
    },
    "papermill": {
     "duration": 0.04176,
     "end_time": "2024-04-11T08:18:21.230891",
     "exception": false,
     "start_time": "2024-04-11T08:18:21.189131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_pad_sequence(data):\n",
    "    global char2int_src, char2int_tgt\n",
    "    x_src, x_tgt = zip(*data)\n",
    "    \n",
    "    # pad 0 (which is uniqueID of the <PAD> token since we designed the vocabularies this way) \n",
    "    # to make each sampled sentences have the same sequence length to make batch training possible\n",
    "    x_src = pad_sequence(x_src, batch_first=True)\n",
    "    x_tgt = pad_sequence(x_tgt, batch_first=True)\n",
    "    \n",
    "    # add <EOS> (End Of Sentence) token at the end of each sampled source and target sentences\n",
    "    eos_src, eos_tgt = encode('<EOS>', char2int_src), encode('<EOS>', char2int_tgt)\n",
    "    x_src = torch.cat((x_src, torch.full((len(x_src), 1), eos_src)), dim=1)\n",
    "    x_tgt = torch.cat((x_tgt, torch.full((len(x_tgt), 1), eos_tgt)), dim=1)\n",
    "    return x_src, x_tgt\n",
    "    \n",
    "# initialize train and test datasets\n",
    "train_dset = LanguageDataset(train_data_src, train_data_tgt, vocab_src, vocab_tgt)\n",
    "test_dset = LanguageDataset(test_data_src, test_data_tgt, vocab_src, vocab_tgt)\n",
    "\n",
    "# initialize train and test iterators\n",
    "train_iterator = DataLoader(train_dset, BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=custom_pad_sequence, pin_memory=True)\n",
    "test_iterator = DataLoader(test_dset, BATCH_SIZE, shuffle=False, collate_fn=custom_pad_sequence, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7e429d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:21.287809Z",
     "iopub.status.busy": "2024-04-11T08:18:21.287119Z",
     "iopub.status.idle": "2024-04-11T08:18:21.295178Z",
     "shell.execute_reply": "2024-04-11T08:18:21.294314Z"
    },
    "papermill": {
     "duration": 0.038839,
     "end_time": "2024-04-11T08:18:21.297284",
     "exception": false,
     "start_time": "2024-04-11T08:18:21.258445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()  \n",
    "        self.embedding_layer = nn.Embedding(input_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flip(x, dims=[1])\n",
    "        x = self.embedding_layer(x)\n",
    "        x, (hidden_state, cell_state) = self.lstm(x)\n",
    "        return x, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00916d69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:21.353074Z",
     "iopub.status.busy": "2024-04-11T08:18:21.352724Z",
     "iopub.status.idle": "2024-04-11T08:18:21.361119Z",
     "shell.execute_reply": "2024-04-11T08:18:21.360192Z"
    },
    "papermill": {
     "duration": 0.038705,
     "end_time": "2024-04-11T08:18:21.363184",
     "exception": false,
     "start_time": "2024-04-11T08:18:21.324479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n",
    "        super().__init__()  \n",
    "        self.embedding_layer = nn.Embedding(input_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        x = self.embedding_layer(x)\n",
    "        x, (hidden_state, cell_state) = self.lstm(x, (hidden_state, cell_state))\n",
    "        x = self.fc(x)\n",
    "        return x, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbbb34e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:21.418857Z",
     "iopub.status.busy": "2024-04-11T08:18:21.418476Z",
     "iopub.status.idle": "2024-04-11T08:18:21.432385Z",
     "shell.execute_reply": "2024-04-11T08:18:21.431508Z"
    },
    "papermill": {
     "duration": 0.044128,
     "end_time": "2024-04-11T08:18:21.434436",
     "exception": false,
     "start_time": "2024-04-11T08:18:21.390308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, max_len=10):\n",
    "    # global variables\n",
    "    global DEVICE, char2int_src, char2int_tgt, int2char_tgt\n",
    "    # set encoder and decoder to evaluation mode\n",
    "    encoder.eval(); decoder.eval()\n",
    "    # get <SOS> token ID for decoder's first forward pass and \n",
    "    # get <EOS> token ID to add it to the end of the sentence that will be translated\n",
    "    sos_tgt = encode('<SOS>', char2int_tgt)\n",
    "    eos_src = encode('<EOS>', char2int_src)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        # encode the input sentence\n",
    "        x = torch.tensor([encode(token, char2int_src) for token in tokenize([sentence])]).view(1, -1)\n",
    "        # add <EOS> token at the end of the input sentence\n",
    "        x = torch.cat((x, torch.full((1, 1), eos_src)), dim=1).long().to(DEVICE)\n",
    "        \n",
    "        # encoder forward pass\n",
    "        _, encoder_hidden_state, encoder_cell_state = encoder(x)        \n",
    "            \n",
    "        # create <SOS> token as the first input token for the decoder pass\n",
    "        next_token = torch.full((1, 1), sos_tgt, dtype=torch.long).to(DEVICE)\n",
    "        # rename encoder's hidden and cell state tensors to ease the decoder loop below\n",
    "        decoder_hidden_state = encoder_hidden_state\n",
    "        decoder_call_state = encoder_cell_state\n",
    "            \n",
    "        translation = []\n",
    "        # generate max_len character at most\n",
    "        for _ in range(max_len):\n",
    "            # decoder forward pass\n",
    "            logits, decoder_hidden_state, decoder_call_state = decoder(next_token, decoder_hidden_state, decoder_call_state) \n",
    "            # get the next token\n",
    "            next_token = torch.argmax(logits.view(-1))\n",
    "            # get the next character\n",
    "            next_char = decode(next_token.item(), int2char_tgt)\n",
    "            \n",
    "            # if <EOS> is predicted as the next char, break the generation loop\n",
    "            if next_char == '<EOS>':\n",
    "                break\n",
    "            else:\n",
    "                translation.append(next_char) \n",
    "            \n",
    "            next_token = next_token.view(1, -1)\n",
    "\n",
    "        translated_sentence = ' '.join(translation)\n",
    "        return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a5da64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:21.486940Z",
     "iopub.status.busy": "2024-04-11T08:18:21.486642Z",
     "iopub.status.idle": "2024-04-11T08:18:21.496874Z",
     "shell.execute_reply": "2024-04-11T08:18:21.496032Z"
    },
    "papermill": {
     "duration": 0.038941,
     "end_time": "2024-04-11T08:18:21.499136",
     "exception": false,
     "start_time": "2024-04-11T08:18:21.460195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, iterator):\n",
    "    # global variables\n",
    "    global DEVICE, char2int_tgt\n",
    "    # set encoder and decoder to evaluation mode\n",
    "    encoder.eval(); decoder.eval()\n",
    "    # initialize the loss sum\n",
    "    loss_sum = 0.0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        # iterate over batches\n",
    "        for iter_idx, (x_src, x_tgt) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "            # carry tensors to available device\n",
    "            x_src, x_tgt = x_src.to(DEVICE), x_tgt.to(DEVICE)\n",
    "            # encoder forward pass\n",
    "            _, encoder_hidden_state, encoder_cell_state = encoder(x_src)\n",
    "            \n",
    "            # create a tensor only containing <SOS> token as input for the decoder\n",
    "            batch_size = len(x_src)  # get current batch size\n",
    "            sos_tgt = encode('<SOS>', char2int_tgt)\n",
    "            decoder_input = torch.full((batch_size, 1), sos_tgt, dtype=torch.long).to(DEVICE)\n",
    "            # rename the hidden state and cell state variables for loop below\n",
    "            decoder_hidden_state, decoder_cell_state = encoder_hidden_state, encoder_cell_state\n",
    "            \n",
    "            # initialize a list to store logits computed for each target token\n",
    "            logits_all = []\n",
    "            # iterate over target sequence\n",
    "            for tgt_idx in range(x_tgt.shape[1]):\n",
    "                # decoder forward pass\n",
    "                logits, decoder_hidden_state, decoder_cell_state = decoder(decoder_input, decoder_hidden_state, decoder_cell_state)\n",
    "                # store logits\n",
    "                logits_all.append(logits)\n",
    "                # get the next target token as input for the next decoder forward pass\n",
    "                decoder_input = x_tgt[:,[tgt_idx]]\n",
    "            \n",
    "            # stack stored logits and compute loss\n",
    "            logits_stacked = torch.hstack(logits_all)\n",
    "            B, S, C = logits_stacked.shape # B: batch size, S: seq length, C: channnel (or embed) size\n",
    "            loss = F.cross_entropy(logits_stacked.view(B*S, C), x_tgt.view(-1), ignore_index=pad_tgt)\n",
    "            \n",
    "            # add batch loss to total loss sum\n",
    "            loss_sum += loss.item()\n",
    "        \n",
    "    # compute avg loss\n",
    "    loss_avg = loss_sum / len(iterator)\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6897e4b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T08:18:21.556004Z",
     "iopub.status.busy": "2024-04-11T08:18:21.555483Z",
     "iopub.status.idle": "2024-04-11T12:19:26.832808Z",
     "shell.execute_reply": "2024-04-11T12:19:26.831812Z"
    },
    "papermill": {
     "duration": 14465.307223,
     "end_time": "2024-04-11T12:19:26.834951",
     "exception": false,
     "start_time": "2024-04-11T08:18:21.527728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:33<00:00,  5.89it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 || train loss = 5.454\ttest loss = 4.452\n",
      "\n",
      "The best model is found and saved. Current best test loss = 4.452\n",
      "\n",
      "Tom is very experienced <---> tom çok iyi değil mi\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> ben onu bir şey değilim değilim değilim değilim değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sadece sık sık sık sık\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu kadar çok iyi değil mi mi\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'ye bir şey verdi verdi\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> sana geri geri geri geri\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz biraz daha görünüyor mu\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mi değil mi mi\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom mary'nin bir hafta ile kadar\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir daha iyi olur\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.92it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 02 || train loss = 3.994\ttest loss = 3.693\n",
      "\n",
      "The best model is found and saved. Current best test loss = 3.693\n",
      "\n",
      "Tom is very experienced <---> tom çok iyi değil mi\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> ben onun bir şey olduğundan emin değilim değilim değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık sık yardım ederim\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok fazla bir şey değil mi\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'ye bir tane satın aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer geri geri gelecek geri\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz su su yapalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom iyi mi\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom dün gece bir mektup geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir iş yaptı\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 03 || train loss = 3.301\ttest loss = 3.246\n",
      "\n",
      "The best model is found and saved. Current best test loss = 3.246\n",
      "\n",
      "Tom is very experienced <---> tom çok iyi değil mi\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onun bir şey olduğundan emin değilim değilim değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben genellikle sık yemek yemem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı bir şey değil mi\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir tane ödünç aldı aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer geri geri seni geri\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz su alalım alalım al\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom da mı mı\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom dün gece bir mektup geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir şekilde yaptı\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:32<00:00,  5.90it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 04 || train loss = 2.823\ttest loss = 2.947\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.947\n",
      "\n",
      "Tom is very experienced <---> tom çok iyi bir şekilde\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onun bir şey olduğundan emin değilim değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık sık yemek yemem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı bir şekilde değildir\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir parça ödünç aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen geri gelebilirsin gidebilirsin misin\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom da mı mı\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom dün gece bir mektup geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir hediye iyidir\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:32<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05 || train loss = 2.463\ttest loss = 2.737\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.737\n",
      "\n",
      "Tom is very experienced <---> tom çok iyi değil mi\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> ben onun bir hata olduğundan emin değilim değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık sık izin verme\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı bir şekilde değildir\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir parça ödünç aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen geri gelebilirsin gelebilirsin gelir misin\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom da mı mı\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom dün gece bir araba geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü çalar\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:33<00:00,  5.89it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 06 || train loss = 2.177\ttest loss = 2.573\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.573\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli değil mi\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onun bir şekilde yaptığını emin değilim değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık izin verme değilim\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı bir şekilde oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir şey aldı aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin seni geri gelebilirsin\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım gidelim\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom da mı mü\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gece mary'ye geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü hissediyor\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:22<00:00, 29.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 07 || train loss = 1.942\ttest loss = 2.457\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.457\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli değil mi\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onun bir şey olmadığına emin değilim değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık izin verme vermem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir şey aldı aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gelebilirsin gelir olur\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım gidelim\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom da mi mı\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom mary'nin bir gece geçirdi geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü çalar\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 08 || train loss = 1.742\ttest loss = 2.363\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.363\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli değil mi\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onun bir kişinin olduğunu emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık telefon etmiyorum istemiyorum\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı bir şekilde oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir şey ödünç aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen seni geri gelebilirsin gelir olur\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mi geliyor mu\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gece mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü çalar\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 09 || train loss = 1.570\ttest loss = 2.284\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.284\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık izin verme vermem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir şey ödünç aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin geri gelebilirsin gelir olur\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mi iyi mi\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gece mary ile geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücüdür\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:30<00:00,  5.92it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 || train loss = 1.421\ttest loss = 2.228\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.228\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onun bir şekilde olduğundan emin değilim değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık dikkat vermem izin verme\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir şey ödünç aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gelebilirsin gelebilirsin olur musun\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom da mi midir mı\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gece mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü arıyor\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 || train loss = 1.289\ttest loss = 2.181\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.181\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> ben onun bir hata olduğundan emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık pes etmem izin verme\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı bir yol oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir şey ödünç aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gelebilirsin gelir olur\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu mi yoksa bir şey mi\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gece mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü çalar\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 || train loss = 1.173\ttest loss = 2.146\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.146\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak o kadar emin değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun vermem izin verme\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor bir şey oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gidebilirsin gelebilirsin gelir olur\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu mi yoksa bir şey mi\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gece mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücüdür\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 || train loss = 1.070\ttest loss = 2.114\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.114\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak o kadar emin değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun vermem izin vermiyorum\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor oluyor mu\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gidebilirsin gelebilirsin gelebilirsin olur musun\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım yapalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yapıyor mu\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gece mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü çalar\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 || train loss = 0.980\ttest loss = 2.092\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.092\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak o kadar emin değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık dikkat etmem izin verme\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor oluyor mu\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gidebilirsin gelebilirsin olur musun\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yapıyor mu yoksa\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gece mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü sürücü\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 || train loss = 0.901\ttest loss = 2.066\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.066\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun boyun vermem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor oluyor mu\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gidebilirsin olur musun\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yapıyor mu yoksa\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gecede için mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücüdür\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 || train loss = 0.832\ttest loss = 2.051\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.051\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir şekilde olduğundan emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun boyun vermem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor kadar hızlı oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gidebilirsin gelebilirsin gelir misin\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım gidelim\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yapıyor mu yoksa bir şey mi\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gecede için mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü sürücü veriyor\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:30<00:00,  5.92it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 || train loss = 0.772\ttest loss = 2.034\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.034\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun boyun vermem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor oluyor mu\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gidebilirsin gelir olur musun\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yapıyor mu yoksa bir şey midir\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gecede için mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücüdür\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:30<00:00,  5.92it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 || train loss = 0.718\ttest loss = 2.029\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.029\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun boyun vermem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor kadar hızlı oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gidebilirsin gelir misin\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım gidelim\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu mi yoksa bir şey mi\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gecede için mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü sürücü çalar\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:31<00:00,  5.91it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 || train loss = 0.670\ttest loss = 2.023\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.023\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun vermem değilim\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor kadar hızlı oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gidebilirsin gelebilirsin gelir olur musun\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım görelim\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yapıyor mu yoksa bir şey mi\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gecede için mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü çalar\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:32<00:00,  5.90it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 || train loss = 0.627\ttest loss = 2.022\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.022\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir kişinin olarak emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun boyun vermem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor oluyor mu\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gidebilirsin gelir misin\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yapıyor mu yoksa tom mu\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gecede için dün gece geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü sürücü\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:30<00:00,  5.93it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 || train loss = 0.588\ttest loss = 2.022\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.022\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir insanın olarak emin değilim değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun boyun vermem\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor çok hızlı oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gidebilirsin gelir misin\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım alalım\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yapıyor mu yoksa bir şey midir\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gecede için mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü sürücü\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:33<00:00,  5.89it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 || train loss = 0.552\ttest loss = 2.021\n",
      "\n",
      "The best model is found and saved. Current best test loss = 2.021\n",
      "\n",
      "Tom is very experienced <---> tom çok deneyimli oluyor\n",
      "Correct translation: Tom çok deneyimli\n",
      "---\n",
      "I'm not sure I see that as a problem <---> onu bir olarak o kadar emin değilim\n",
      "Correct translation: Bunu bir sorun olarak gördüğümden emin değilim\n",
      "---\n",
      "I don't give guitars away often <---> ben sık sık boyun boyun vermem misin\n",
      "Correct translation: Gitarları genellikle elden çıkarmam\n",
      "---\n",
      "This is happening way too fast <---> bu çok hızlı oluyor çok hızlı oluyor\n",
      "Correct translation: Bu çok çabuk oluyor\n",
      "---\n",
      "Tom borrowed a flashlight from Mary <---> tom mary'den bir el feneri aldı\n",
      "Correct translation: Tom Mary'den bir el feneri ödünç aldı\n",
      "---\n",
      "If you come back soon, you may go <---> eğer istersen gelebilirsin gidebilirsin gelir gelir misin\n",
      "Correct translation: Yakın bir zamanda geleceksen gidebilirsin\n",
      "---\n",
      "Let's get some ice cream <---> biraz dondurma alalım alalım görelim\n",
      "Correct translation: Biraz dondurma alalım\n",
      "---\n",
      "Is Tom reachable <---> tom mu yoksa mı mü\n",
      "Correct translation: Tom ulaşılabilir mi\n",
      "---\n",
      "Tom spent a sleepless night thinking of Mary <---> tom geceyi bir gecede için mary'nin geçirdi geçirdi\n",
      "Correct translation: Tom Mary'yi düşünerek uykusuz bir gece geçirdi\n",
      "---\n",
      "Tom is a better driver than Mary <---> tom mary'den daha iyi bir sürücü sürücü veriyor\n",
      "Correct translation: Tom Mary'den daha iyi bir sürücü\n",
      "---\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:33<00:00,  5.89it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 || train loss = 0.519\ttest loss = 2.027\n",
      "\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:33<00:00,  5.89it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 || train loss = 0.489\ttest loss = 2.024\n",
      "\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:32<00:00,  5.90it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 29.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 || train loss = 0.461\ttest loss = 2.032\n",
      "\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:29<00:00,  5.94it/s]\n",
      "100%|██████████| 671/671 [00:22<00:00, 29.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 || train loss = 0.435\ttest loss = 2.038\n",
      "\n",
      "--------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3024/3024 [08:29<00:00,  5.93it/s]\n",
      "100%|██████████| 671/671 [00:23<00:00, 28.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 || train loss = 0.411\ttest loss = 2.044\n",
      "\n",
      "A better model has not been found in the last 5 epochs. Early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the encoder\n",
    "encoder = Encoder(\n",
    "    input_size=vocab_src_size,\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    ").to(DEVICE)\n",
    "\n",
    "# initialize the decoder\n",
    "decoder = Decoder(\n",
    "    input_size=vocab_tgt_size,\n",
    "    embed_size=EMBED_SIZE, \n",
    "    hidden_size=HIDDEN_SIZE, \n",
    "    num_layers=NUM_LAYERS,\n",
    ").to(DEVICE)\n",
    "\n",
    "# initialize encoder and decoder optimizers\n",
    "optimizer_encoder = torch.optim.AdamW(encoder.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_decoder = torch.optim.AdamW(decoder.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# init the best test loss as positive inifinity\n",
    "best_test_loss = float('inf')\n",
    "best_streak_count = 0\n",
    "\n",
    "# select some example sentences from test set to translate during training\n",
    "n_example_sentence = 10\n",
    "example_sentence_indices = np.random.randint(low=0, high=len(test_data_src), size=n_example_sentence)\n",
    "\n",
    "# iterate over epochs\n",
    "for epoch_idx in range(1, N_EPOCHS+1):\n",
    "    # initialize train loss\n",
    "    loss_train = 0.0\n",
    "    # set encoder and decoder to train mode\n",
    "    encoder.train(); decoder.train()\n",
    "    \n",
    "    # iterate over batches\n",
    "    for iter_idx, (x_src, x_tgt) in tqdm(enumerate(train_iterator), total=len(train_iterator)):\n",
    "        # carry tensors to available device\n",
    "        x_src, x_tgt = x_src.to(DEVICE), x_tgt.to(DEVICE)\n",
    "        # encoder forward pass\n",
    "        _, encoder_hidden_state, encoder_cell_state = encoder(x_src)\n",
    "        \n",
    "        # create a tensor only containing <SOS> token as input for the decoder\n",
    "        sos_tgt = encode('<SOS>', char2int_tgt)\n",
    "        decoder_input = torch.full((BATCH_SIZE, 1), sos_tgt, dtype=torch.long).to(DEVICE)\n",
    "        \n",
    "        # rename the hidden state and cell state variables for loop below\n",
    "        decoder_hidden_state, decoder_cell_state = encoder_hidden_state, encoder_cell_state\n",
    "        \n",
    "        # initialize a list to store logits computed for each target token\n",
    "        logits_all = []\n",
    "        # itearate over target sequence\n",
    "        for tgt_idx in range(x_tgt.shape[1]):\n",
    "            # decoder forward pass\n",
    "            logits, decoder_hidden_state, decoder_cell_state = decoder(decoder_input, decoder_hidden_state, decoder_cell_state)\n",
    "            # store logits\n",
    "            logits_all.append(logits)\n",
    "            # get the next target token as input for the next decoder forward pass\n",
    "            decoder_input = x_tgt[:,[tgt_idx]]\n",
    "        \n",
    "        # stack stored logits and compute loss\n",
    "        logits_stacked = torch.hstack(logits_all)\n",
    "        pad_tgt = encode('<PAD>', char2int_tgt)        \n",
    "        B, S, C = logits_stacked.shape  # B: batch size, S: seq length, C: channnel (or embed) size\n",
    "        loss = F.cross_entropy(logits_stacked.view(B*S, C), x_tgt.view(-1), ignore_index=pad_tgt)\n",
    "        \n",
    "        # update gradients\n",
    "        optimizer_encoder.zero_grad()\n",
    "        optimizer_decoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_encoder.step()\n",
    "        optimizer_decoder.step()\n",
    "        \n",
    "        # add batch loss to total loss sum\n",
    "        loss_train += loss.item()\n",
    "\n",
    "    # print epoch logs\n",
    "    loss_train /= len(train_iterator)\n",
    "    loss_test = evaluate(encoder, decoder, test_iterator)\n",
    "    print(f\"epoch {epoch_idx:02} || train loss = {loss_train:.3f}\\ttest loss = {loss_test:.3f}\", end='\\n\\n')\n",
    "    \n",
    "    # save the current model as the best model if the current test loss is the least achieved \n",
    "    if loss_test < best_test_loss:\n",
    "        # save the curent encoder and decoder's parameters as the best parameters\n",
    "        torch.save(encoder.state_dict(), BEST_ENCODER_FILEPATH)\n",
    "        torch.save(decoder.state_dict(), BEST_DECODER_FILEPATH)\n",
    "        # replace the best test loss with the current best loss\n",
    "        best_test_loss = loss_test\n",
    "        # reset early stoppping counter \n",
    "        best_streak_count = 0\n",
    "        # display info\n",
    "        print(f'The best model is found and saved. Current best test loss = {best_test_loss:.3f}\\n')\n",
    "        # translate example sentences\n",
    "        for example_idx in example_sentence_indices:\n",
    "            sentence = test_data_src[example_idx]\n",
    "            translation_gt = test_data_tgt[example_idx]\n",
    "            translation = translate(sentence, encoder, decoder)\n",
    "            print(f\"{sentence} <---> {translation}\")\n",
    "            print(f\"Correct translation: {translation_gt}\")\n",
    "            print(\"---\")\n",
    "    else:\n",
    "        # update early stoppping counter \n",
    "        best_streak_count += 1\n",
    "\n",
    "    # check early stopping condition\n",
    "    if best_streak_count == EARLY_STOPPING_STEP_SIZE:\n",
    "        print(f\"A better model has not been found in the last {EARLY_STOPPING_STEP_SIZE} epochs. Early stopping...\")\n",
    "        break\n",
    "        \n",
    "    print(\"--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07e65fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T12:19:41.414227Z",
     "iopub.status.busy": "2024-04-11T12:19:41.413741Z",
     "iopub.status.idle": "2024-04-11T12:19:42.639670Z",
     "shell.execute_reply": "2024-04-11T12:19:42.638822Z"
    },
    "papermill": {
     "duration": 8.399445,
     "end_time": "2024-04-11T12:19:42.641645",
     "exception": false,
     "start_time": "2024-04-11T12:19:34.242200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder and Decoder are initialized and the best model parameters are loaded.\n"
     ]
    }
   ],
   "source": [
    "# reinitialize encoder\n",
    "best_encoder = Encoder(\n",
    "    input_size=vocab_src_size,\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    ").to(DEVICE)\n",
    "# load best encoder's parameters\n",
    "best_encoder.load_state_dict(torch.load(BEST_ENCODER_FILEPATH))\n",
    "\n",
    "# reinitialize decoder\n",
    "best_decoder = Decoder(\n",
    "    input_size=vocab_tgt_size,\n",
    "    embed_size=EMBED_SIZE, \n",
    "    hidden_size=HIDDEN_SIZE, \n",
    "    num_layers=NUM_LAYERS,\n",
    ").to(DEVICE)\n",
    "# load best decoder's parameters\n",
    "best_decoder.load_state_dict(torch.load(BEST_DECODER_FILEPATH))\n",
    "print(\"Encoder and Decoder are initialized and the best model parameters are loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e0d347a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T12:19:57.108966Z",
     "iopub.status.busy": "2024-04-11T12:19:57.108546Z",
     "iopub.status.idle": "2024-04-11T12:19:57.120004Z",
     "shell.execute_reply": "2024-04-11T12:19:57.118954Z"
    },
    "papermill": {
     "duration": 7.250991,
     "end_time": "2024-04-11T12:19:57.121858",
     "exception": false,
     "start_time": "2024-04-11T12:19:49.870867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like hiking <---> ben yürüyüşe severim severim severim\n"
     ]
    }
   ],
   "source": [
    "# simple example\n",
    "sentence = \"I like hiking\"\n",
    "translation = translate(sentence, best_encoder, best_decoder)\n",
    "print(f\"{sentence} <---> {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b25c9dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T12:20:11.474027Z",
     "iopub.status.busy": "2024-04-11T12:20:11.473617Z",
     "iopub.status.idle": "2024-04-11T12:20:11.488214Z",
     "shell.execute_reply": "2024-04-11T12:20:11.487210Z"
    },
    "papermill": {
     "duration": 7.254663,
     "end_time": "2024-04-11T12:20:11.490146",
     "exception": false,
     "start_time": "2024-04-11T12:20:04.235483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's difficult choosing between what's right and what's wrong, but you have to make the choice <---> doğru olup olmadığı ne olduğu ama seçim yapmak arasında seçim\n",
      "Correct translation: Neyin doğru ve neyin yanlış olduğu arasında seçim yapmak zor ama seçim yapmak zorundasın\n"
     ]
    }
   ],
   "source": [
    "# harder example\n",
    "idx = -100\n",
    "sentence = test_data_src[idx]\n",
    "translation_gt = test_data_tgt[idx]\n",
    "\n",
    "translation = translate(sentence, best_encoder, best_decoder)\n",
    "print(f\"{sentence} <---> {translation}\")\n",
    "print(f\"Correct translation: {translation_gt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b38ff",
   "metadata": {
    "papermill": {
     "duration": 7.278489,
     "end_time": "2024-04-11T12:20:25.945031",
     "exception": false,
     "start_time": "2024-04-11T12:20:18.666542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14569.786528,
   "end_time": "2024-04-11T12:20:34.735499",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-11T08:17:44.948971",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
