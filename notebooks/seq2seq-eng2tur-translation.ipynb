{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\n\nfrom tqdm import tqdm\nimport numpy as np\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-10T20:11:52.476956Z","iopub.execute_input":"2024-04-10T20:11:52.477316Z","iopub.status.idle":"2024-04-10T20:11:52.482229Z","shell.execute_reply.started":"2024-04-10T20:11:52.477292Z","shell.execute_reply":"2024-04-10T20:11:52.481353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set seeds for reproducibility\nSEED = 123\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:11:52.483203Z","iopub.execute_input":"2024-04-10T20:11:52.483451Z","iopub.status.idle":"2024-04-10T20:11:52.493464Z","shell.execute_reply.started":"2024-04-10T20:11:52.483430Z","shell.execute_reply":"2024-04-10T20:11:52.492556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set URL to download data\ntranslation_data_url = \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/translation/EN2TR.txt\"\n# get data filename\ntranslation_data_filename = os.path.basename(translation_data_url)\n\n# download the data in local if it doesn't already exist\nif not os.path.exists(translation_data_filename):\n    try:\n        !wget $translation_data_url\n        print(\"File is succesfully downloaded.\")\n    except Exception as e:\n        print(f\"Could not download the book from {translation_data_url}\")\n        print(e)\nelse:\n    print(\"File has already been downloaded.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:11:53.808721Z","iopub.execute_input":"2024-04-10T20:11:53.809110Z","iopub.status.idle":"2024-04-10T20:11:56.785798Z","shell.execute_reply.started":"2024-04-10T20:11:53.809077Z","shell.execute_reply":"2024-04-10T20:11:56.784706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define hyperparameters\nN_EPOCHS = 30\nBATCH_SIZE = 128\nLEARNING_RATE = 1e-3\nEMBED_SIZE = 256\nHIDDEN_SIZE = 512\nNUM_LAYERS = 1\nTEST_SIZE = 0.2\nSAMPLE_RATIO = 1.0\nEARLY_STOPPING_STEP_SIZE = 5\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nBEST_ENCODER_FILEPATH = 'best_encoder.pt'\nBEST_DECODER_FILEPATH = 'best_decoder.pt'\n\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:11:56.787697Z","iopub.execute_input":"2024-04-10T20:11:56.788012Z","iopub.status.idle":"2024-04-10T20:11:56.825552Z","shell.execute_reply.started":"2024-04-10T20:11:56.787982Z","shell.execute_reply":"2024-04-10T20:11:56.824567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(fp, sep='\\t', remove_last_char=False, drop_first=False):\n    with open(fp, mode='r') as infile:\n        sentences = [row.strip().split(sep) for idx, row in enumerate(infile)]\n        if drop_first:\n            sentences = sentences[1:]\n    sentences_src, sentences_tgt = zip(*sentences)\n    if remove_last_char:\n        sentences_src = [sentence[:-1] for sentence in sentences_src]\n        sentences_tgt = [sentence[:-1] for sentence in sentences_tgt]\n    return sentences_src, sentences_tgt","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:11:56.826802Z","iopub.execute_input":"2024-04-10T20:11:56.827088Z","iopub.status.idle":"2024-04-10T20:11:56.834358Z","shell.execute_reply.started":"2024-04-10T20:11:56.827064Z","shell.execute_reply":"2024-04-10T20:11:56.833570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load all sentences for both source and target languages\nall_sentences_src, all_sentences_tgt = load_data(translation_data_filename, remove_last_char=True)\nassert len(all_sentences_src) == len(all_sentences_tgt)  # sanity check\n\n# get the number of all sentences\nn_all_sentences = len(all_sentences_src)\nprint(f\"There are {n_all_sentences} in total\")\n\n### sample sentences with a SAMPLE_RATIO to get a portion to use in training\n# get the number of (sampled) sentences\nn_sentences = int(n_all_sentences * SAMPLE_RATIO)\n# get the sampled source and target sentences\nsentences_src, sentences_tgt = all_sentences_src[:n_sentences], all_sentences_tgt[:n_sentences]\nprint(f\"There are {n_sentences} in total after sampling %{SAMPLE_RATIO*100} of all sentences\")\n\n# display some example translation from the data\nprint('\\nExamples:')\nfor idx in np.random.randint(low=0, high=n_sentences, size=5):\n    print(f\"{sentences_src[idx]} <---> {sentences_tgt[idx]}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:11:56.836248Z","iopub.execute_input":"2024-04-10T20:11:56.836559Z","iopub.status.idle":"2024-04-10T20:11:58.658155Z","shell.execute_reply.started":"2024-04-10T20:11:56.836536Z","shell.execute_reply":"2024-04-10T20:11:58.657210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### split sentences into train and test sets\n# set the number of test sentences\nn_test = int(n_sentences * TEST_SIZE)\n# randomly select test sentence indices\ntest_indices = np.random.randint(low=0, high=n_sentences, size=n_test)\n\n# split sentences into train and test, source and target language sets\ntrain_data_src, train_data_tgt = [], []\ntest_data_src, test_data_tgt = [], []\nfor i in tqdm(range(n_sentences)):\n    if i in test_indices:\n        test_data_src.append(sentences_src[i])\n        test_data_tgt.append(sentences_tgt[i])\n    else:\n        train_data_src.append(sentences_src[i])\n        train_data_tgt.append(sentences_tgt[i])\n\n# get the number of train sentences\nn_train = len(train_data_src)\nprint(f\"There {n_train} sentences in train data.\")\n\n# get the number test train sentences\nn_test = len(test_data_src)\nprint(f\"There {n_test} sentences in test data.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:01.056382Z","iopub.execute_input":"2024-04-10T20:12:01.057422Z","iopub.status.idle":"2024-04-10T20:12:23.453556Z","shell.execute_reply.started":"2024-04-10T20:12:01.057384Z","shell.execute_reply":"2024-04-10T20:12:23.452607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define function to tokenize sentences (in a very simple way)\ndef tokenize(sentences):\n    return [el for sentence in sentences for el in sentence.lower().split()]","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:23.455123Z","iopub.execute_input":"2024-04-10T20:12:23.455400Z","iopub.status.idle":"2024-04-10T20:12:23.460676Z","shell.execute_reply.started":"2024-04-10T20:12:23.455375Z","shell.execute_reply":"2024-04-10T20:12:23.459667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define special tokens (we won't use <UNK> but it's a good practise to have it)\nspecial_tokens = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n\n# define source and target language vocabularies by tokenizing sentences\n# (and add special tokens to both vocabularys)\nvocab_src = special_tokens + sorted(list(set(tokenize(sentences_src))))\nvocab_tgt = special_tokens + sorted(list(set(tokenize(sentences_tgt))))\n\n# get the source and target languages' vocabulary sizes\nvocab_src_size = len(vocab_src)\nvocab_tgt_size = len(vocab_tgt)\n\nprint(f\"Vocabulary (SRC) size = {vocab_src_size}\")\nprint(f\"Vocabulary (TGT) size = {vocab_tgt_size}\")\nprint(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:24.499712Z","iopub.execute_input":"2024-04-10T20:12:24.500433Z","iopub.status.idle":"2024-04-10T20:12:26.129238Z","shell.execute_reply.started":"2024-04-10T20:12:24.500398Z","shell.execute_reply":"2024-04-10T20:12:26.128318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the mappings (as dictionary) of \n# 'a token (from the vocab) to a unique ID' ---> 'char2int'\n# and\n# 'a unique ID to a token (from the vocab)'  ---> 'int2char'\n# for both source and target languages\nchar2int_src = {c: idx for idx, c in enumerate(vocab_src)}\nint2char_src = {idx: c for idx, c in enumerate(vocab_src)}\n\nchar2int_tgt = {c: idx for idx, c in enumerate(vocab_tgt)}\nint2char_tgt = {idx: c for idx, c in enumerate(vocab_tgt)}\n\n# define the encode() that encodes/converts a token to a unique ID \ndef encode(character, char2int):\n    return char2int[character]\n\n# define the encode() that decodes/converts back a unique ID to a token\ndef decode(integer, int2char):\n    return int2char[integer]\n\n# show an example of how encode() and decode() operate\nsentence_src = 'What time is it?'\nsentence_src_encoded = [encode(token, char2int_src) for token in tokenize([sentence_src])]\nprint(f\"'{sentence_src}' is encoded as {sentence_src_encoded}.\")\n\nsentence_src_encoded_decoded = [decode(token, int2char_src) for token in sentence_src_encoded]\nprint(f\"'{sentence_src_encoded}' is encoded as '{' '.join(sentence_src_encoded_decoded)}'.\")\nprint(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:26.131201Z","iopub.execute_input":"2024-04-10T20:12:26.131597Z","iopub.status.idle":"2024-04-10T20:12:26.201027Z","shell.execute_reply.started":"2024-04-10T20:12:26.131561Z","shell.execute_reply":"2024-04-10T20:12:26.200099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the LanguageDataset as an instance of torch.nn.Dataset\nclass LanguageDataset(Dataset):\n    def __init__(self, sentences_src, sentences_tgt, vocab_src, vocab_tgt):\n        super().__init__()\n        self.sentences_src = sentences_src\n        self.sentences_tgt = sentences_tgt\n        self.vocab_src = vocab_src\n        self.vocab_tgt = vocab_tgt\n\n    def __len__(self):\n        return len(self.sentences_src)\n\n    def __getitem__(self, idx):\n        x_src = torch.tensor(\n            [encode(token, char2int_src) for token in tokenize([self.sentences_src[idx]])], \n            dtype=torch.long\n        )\n        x_tgt = torch.tensor(\n            [encode(token, char2int_tgt) for token in tokenize([self.sentences_tgt[idx]])],\n            dtype=torch.long\n        )\n        return x_src, x_tgt","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:26.202253Z","iopub.execute_input":"2024-04-10T20:12:26.202614Z","iopub.status.idle":"2024-04-10T20:12:26.210355Z","shell.execute_reply.started":"2024-04-10T20:12:26.202581Z","shell.execute_reply":"2024-04-10T20:12:26.209510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_pad_sequence(data):\n    global char2int_src, char2int_tgt\n    x_src, x_tgt = zip(*data)\n    \n    # pad 0 (which is uniqueID of the <PAD> token since we designed the vocabularies this way) \n    # to make each sampled sentences have the same sequence length to make batch training possible\n    x_src = pad_sequence(x_src, batch_first=True)\n    x_tgt = pad_sequence(x_tgt, batch_first=True)\n    \n    # add <EOS> (End Of Sentence) token at the end of each sampled source and target sentences\n    eos_src, eos_tgt = encode('<EOS>', char2int_src), encode('<EOS>', char2int_tgt)\n    x_src = torch.cat((x_src, torch.full((len(x_src), 1), eos_src)), dim=1)\n    x_tgt = torch.cat((x_tgt, torch.full((len(x_tgt), 1), eos_tgt)), dim=1)\n    return x_src, x_tgt\n    \n# initialize train and test datasets\ntrain_dset = LanguageDataset(train_data_src, train_data_tgt, vocab_src, vocab_tgt)\ntest_dset = LanguageDataset(test_data_src, test_data_tgt, vocab_src, vocab_tgt)\n\n# initialize train and test iterators\ntrain_iterator = DataLoader(train_dset, BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=custom_pad_sequence, pin_memory=True)\ntest_iterator = DataLoader(test_dset, BATCH_SIZE, shuffle=False, collate_fn=custom_pad_sequence, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:26.212195Z","iopub.execute_input":"2024-04-10T20:12:26.212489Z","iopub.status.idle":"2024-04-10T20:12:26.225488Z","shell.execute_reply.started":"2024-04-10T20:12:26.212436Z","shell.execute_reply":"2024-04-10T20:12:26.224588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define Encoder\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n        super().__init__()  \n        self.embedding_layer = nn.Embedding(input_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n\n    def forward(self, x):\n        x = torch.flip(x, dims=[1])\n        x = self.embedding_layer(x)\n        x, (hidden_state, cell_state) = self.lstm(x)\n        return x, hidden_state, cell_state","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:26.240996Z","iopub.execute_input":"2024-04-10T20:12:26.241265Z","iopub.status.idle":"2024-04-10T20:12:26.247108Z","shell.execute_reply.started":"2024-04-10T20:12:26.241236Z","shell.execute_reply":"2024-04-10T20:12:26.246328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define Decoder\nclass Decoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n        super().__init__()  \n        self.embedding_layer = nn.Embedding(input_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, input_size)\n\n    def forward(self, x, hidden_state, cell_state):\n        x = self.embedding_layer(x)\n        x, (hidden_state, cell_state) = self.lstm(x, (hidden_state, cell_state))\n        x = self.fc(x)\n        return x, hidden_state, cell_state","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:26.630015Z","iopub.execute_input":"2024-04-10T20:12:26.630817Z","iopub.status.idle":"2024-04-10T20:12:26.638047Z","shell.execute_reply.started":"2024-04-10T20:12:26.630786Z","shell.execute_reply":"2024-04-10T20:12:26.637142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def translate(sentence, encoder, decoder, max_len=10):\n    # global variables\n    global DEVICE, char2int_src, char2int_tgt, int2char_tgt\n    # set encoder and decoder to evaluation mode\n    encoder.eval(); decoder.eval()\n    # get <SOS> token ID for decoder's first forward pass and \n    # get <EOS> token ID to add it to the end of the sentence that will be translated\n    sos_tgt = encode('<SOS>', char2int_tgt)\n    eos_src = encode('<EOS>', char2int_src)\n    \n    with torch.inference_mode():\n        # encode the input sentence\n        x = torch.tensor([encode(token, char2int_src) for token in tokenize([sentence])]).view(1, -1)\n        # add <EOS> token at the end of the input sentence\n        x = torch.cat((x, torch.full((1, 1), eos_src)), dim=1).long().to(DEVICE)\n        \n        # encoder forward pass\n        _, encoder_hidden_state, encoder_cell_state = encoder(x)        \n            \n        # create <SOS> token as the first input token for the decoder pass\n        next_token = torch.full((1, 1), sos_tgt, dtype=torch.long).to(DEVICE)\n        # rename encoder's hidden and cell state tensors to ease the decoder loop below\n        decoder_hidden_state = encoder_hidden_state\n        decoder_call_state = encoder_cell_state\n            \n        translation = []\n        # generate max_len character at most\n        for _ in range(max_len):\n            # decoder forward pass\n            logits, decoder_hidden_state, decoder_call_state = decoder(next_token, decoder_hidden_state, decoder_call_state) \n            # get the next token\n            next_token = torch.argmax(logits.view(-1))\n            # get the next character\n            next_char = decode(next_token.item(), int2char_tgt)\n            \n            # if <EOS> is predicted as the next char, break the generation loop\n            if next_char == '<EOS>':\n                break\n            else:\n                translation.append(next_char) \n            \n            next_token = next_token.view(1, -1)\n\n        translated_sentence = ' '.join(translation)\n        return translated_sentence","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:27.181500Z","iopub.execute_input":"2024-04-10T20:12:27.182323Z","iopub.status.idle":"2024-04-10T20:12:27.191758Z","shell.execute_reply.started":"2024-04-10T20:12:27.182292Z","shell.execute_reply":"2024-04-10T20:12:27.190822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(encoder, decoder, iterator):\n    # global variables\n    global DEVICE, char2int_tgt\n    # set encoder and decoder to evaluation mode\n    encoder.eval(); decoder.eval()\n    # initialize the loss sum\n    loss_sum = 0.0\n    \n    with torch.inference_mode():\n        # iterate over batches\n        for iter_idx, (x_src, x_tgt) in tqdm(enumerate(iterator), total=len(iterator)):\n            # carry tensors to available device\n            x_src, x_tgt = x_src.to(DEVICE), x_tgt.to(DEVICE)\n            # encoder forward pass\n            _, encoder_hidden_state, encoder_cell_state = encoder(x_src)\n            \n            # create a tensor only containing <SOS> token as input for the decoder\n            batch_size = len(x_src)  # get current batch size\n            sos_tgt = encode('<SOS>', char2int_tgt)\n            decoder_input = torch.full((batch_size, 1), sos_tgt, dtype=torch.long).to(DEVICE)\n            # rename the hidden state and cell state variables for loop below\n            decoder_hidden_state, decoder_cell_state = encoder_hidden_state, encoder_cell_state\n            \n            # initialize a list to store logits computed for each target token\n            logits_all = []\n            # iterate over target sequence\n            for tgt_idx in range(x_tgt.shape[1]):\n                # decoder forward pass\n                logits, decoder_hidden_state, decoder_cell_state = decoder(decoder_input, decoder_hidden_state, decoder_cell_state)\n                # store logits\n                logits_all.append(logits)\n                # get the next target token as input for the next decoder forward pass\n                decoder_input = x_tgt[:,[tgt_idx]]\n            \n            # stack stored logits and compute loss\n            logits_stacked = torch.hstack(logits_all)\n            B, S, C = logits_stacked.shape # B: batch size, S: seq length, C: channnel (or embed) size\n            loss = F.cross_entropy(logits_stacked.view(B*S, C), x_tgt.view(-1), ignore_index=pad_tgt)\n            \n            # add batch loss to total loss sum\n            loss_sum += loss.item()\n        \n    # compute avg loss\n    loss_avg = loss_sum / len(iterator)\n    return loss_avg","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:12:27.578812Z","iopub.execute_input":"2024-04-10T20:12:27.579135Z","iopub.status.idle":"2024-04-10T20:12:27.588912Z","shell.execute_reply.started":"2024-04-10T20:12:27.579110Z","shell.execute_reply":"2024-04-10T20:12:27.587952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize the encoder\nencoder = Encoder(\n    input_size=vocab_src_size,\n    embed_size=EMBED_SIZE,\n    hidden_size=HIDDEN_SIZE,\n    num_layers=NUM_LAYERS,\n).to(DEVICE)\n\n# initialize the decoder\ndecoder = Decoder(\n    input_size=vocab_tgt_size,\n    embed_size=EMBED_SIZE, \n    hidden_size=HIDDEN_SIZE, \n    num_layers=NUM_LAYERS,\n).to(DEVICE)\n\n# initialize encoder and decoder optimizers\noptimizer_encoder = torch.optim.AdamW(encoder.parameters(), lr=LEARNING_RATE)\noptimizer_decoder = torch.optim.AdamW(decoder.parameters(), lr=LEARNING_RATE)\n\n# init the best test loss as positive inifinity\nbest_test_loss = float('inf')\nbest_streak_count = 0\n\n# select some example sentences from test set to translate during training\nn_example_sentence = 10\nexample_sentence_indices = np.random.randint(low=0, high=len(test_data_src), size=n_example_sentence)\n\n# iterate over epochs\nfor epoch_idx in range(1, N_EPOCHS+1):\n    # initialize train loss\n    loss_train = 0.0\n    # set encoder and decoder to train mode\n    encoder.train(); decoder.train()\n    \n    # iterate over batches\n    for iter_idx, (x_src, x_tgt) in tqdm(enumerate(train_iterator), total=len(train_iterator)):\n        # carry tensors to available device\n        x_src, x_tgt = x_src.to(DEVICE), x_tgt.to(DEVICE)\n        # encoder forward pass\n        _, encoder_hidden_state, encoder_cell_state = encoder(x_src)\n        \n        # create a tensor only containing <SOS> token as input for the decoder\n        sos_tgt = encode('<SOS>', char2int_tgt)\n        decoder_input = torch.full((BATCH_SIZE, 1), sos_tgt, dtype=torch.long).to(DEVICE)\n        \n        # rename the hidden state and cell state variables for loop below\n        decoder_hidden_state, decoder_cell_state = encoder_hidden_state, encoder_cell_state\n        \n        # initialize a list to store logits computed for each target token\n        logits_all = []\n        # itearate over target sequence\n        for tgt_idx in range(x_tgt.shape[1]):\n            # decoder forward pass\n            logits, decoder_hidden_state, decoder_cell_state = decoder(decoder_input, decoder_hidden_state, decoder_cell_state)\n            # store logits\n            logits_all.append(logits)\n            # get the next target token as input for the next decoder forward pass\n            decoder_input = x_tgt[:,[tgt_idx]]\n        \n        # stack stored logits and compute loss\n        logits_stacked = torch.hstack(logits_all)\n        pad_tgt = encode('<PAD>', char2int_tgt)        \n        B, S, C = logits_stacked.shape  # B: batch size, S: seq length, C: channnel (or embed) size\n        loss = F.cross_entropy(logits_stacked.view(B*S, C), x_tgt.view(-1), ignore_index=pad_tgt)\n        \n        # update gradients\n        optimizer_encoder.zero_grad()\n        optimizer_decoder.zero_grad()\n        loss.backward()\n        optimizer_encoder.step()\n        optimizer_decoder.step()\n        \n        # add batch loss to total loss sum\n        loss_train += loss.item()\n\n    # print epoch logs\n    loss_train /= len(train_iterator)\n    loss_test = evaluate(encoder, decoder, test_iterator)\n    print(f\"epoch {epoch_idx:02} || train loss = {loss_train:.3f}\\ttest loss = {loss_test:.3f}\", end='\\n\\n')\n    \n    # save the current model as the best model if the current test loss is the least achieved \n    if loss_test < best_test_loss:\n        # save the curent encoder and decoder's parameters as the best parameters\n        torch.save(encoder.state_dict(), BEST_ENCODER_FILEPATH)\n        torch.save(decoder.state_dict(), BEST_DECODER_FILEPATH)\n        # replace the best test loss with the current best loss\n        best_test_loss = loss_test\n        # reset early stoppping counter \n        best_streak_count = 0\n        # display info\n        print(f'The best model is found and saved. Current best test loss = {best_test_loss:.3f}\\n')\n        # translate example sentences\n        for example_idx in example_sentence_indices:\n            sentence = test_data_src[example_idx]\n            translation = translate(sentence, encoder, decoder)\n            print(f\"{sentence} <---> {translation}\")\n    else:\n        # update early stoppping counter \n        best_streak_count += 1\n\n    # check early stopping condition\n    if best_streak_count == EARLY_STOPPING_STEP_SIZE:\n        print(f\"A better model has not been found in the last {EARLY_STOPPING_STEP_SIZE} epochs. Early stopping...\")\n        break\n        \n    print(\"--------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T19:37:32.568669Z","iopub.execute_input":"2024-04-10T19:37:32.569050Z","iopub.status.idle":"2024-04-10T20:06:35.566498Z","shell.execute_reply.started":"2024-04-10T19:37:32.569020Z","shell.execute_reply":"2024-04-10T20:06:35.564922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reinitialize encoder\nbest_encoder = Encoder(\n    input_size=vocab_src_size,\n    embed_size=EMBED_SIZE,\n    hidden_size=HIDDEN_SIZE,\n    num_layers=NUM_LAYERS,\n).to(DEVICE)\n# load best encoder's parameters\nbest_encoder.load_state_dict(torch.load(BEST_ENCODER_FILEPATH))\n\n# reinitialize decoder\nbest_decoder = Decoder(\n    input_size=vocab_tgt_size,\n    embed_size=EMBED_SIZE, \n    hidden_size=HIDDEN_SIZE, \n    num_layers=NUM_LAYERS,\n).to(DEVICE)\n# load best decoder's parameters\nbest_decoder.load_state_dict(torch.load(BEST_DECODER_FILEPATH))\nprint(\"Encoder and Decoder are initialized and the best model parameters are loaded.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:06:38.445550Z","iopub.execute_input":"2024-04-10T20:06:38.446536Z","iopub.status.idle":"2024-04-10T20:06:39.853440Z","shell.execute_reply.started":"2024-04-10T20:06:38.446499Z","shell.execute_reply":"2024-04-10T20:06:39.852246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# simple example\nsentence = \"I like hiking\"\ntranslation = translate(sentence, best_encoder, best_decoder)\nprint(f\"{sentence} <---> {translation}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T20:06:51.636400Z","iopub.execute_input":"2024-04-10T20:06:51.637218Z","iopub.status.idle":"2024-04-10T20:06:51.647681Z","shell.execute_reply.started":"2024-04-10T20:06:51.637181Z","shell.execute_reply":"2024-04-10T20:06:51.646624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# harder example\nsentence = test_data_src[-100]\ntranslation = translate(sentence, best_encoder, best_decoder)\nprint(f\"{sentence} <---> {translation}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}