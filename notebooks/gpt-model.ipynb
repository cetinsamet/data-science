{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-11T18:17:37.992916Z","iopub.status.busy":"2024-04-11T18:17:37.992078Z","iopub.status.idle":"2024-04-11T18:17:44.941711Z","shell.execute_reply":"2024-04-11T18:17:44.939727Z","shell.execute_reply.started":"2024-04-11T18:17:37.992881Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch\n","\n","from transformers import AutoTokenizer\n","\n","from nltk.tokenize import word_tokenize\n","from tqdm import tqdm\n","import numpy as np\n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:44.943597Z","iopub.status.busy":"2024-04-11T18:17:44.943173Z","iopub.status.idle":"2024-04-11T18:17:44.951369Z","shell.execute_reply":"2024-04-11T18:17:44.950403Z","shell.execute_reply.started":"2024-04-11T18:17:44.943572Z"},"trusted":true},"outputs":[],"source":["# set seeds for reproducibility\n","SEED = 123\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:44.952636Z","iopub.status.busy":"2024-04-11T18:17:44.952342Z","iopub.status.idle":"2024-04-11T18:17:44.965188Z","shell.execute_reply":"2024-04-11T18:17:44.964355Z","shell.execute_reply.started":"2024-04-11T18:17:44.952609Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'TheOdyssey': 'https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/TheOdyssey_Homer.txt',\n"," 'PrideAndPrejudice': 'https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/PrideAndPrejudice_JaneAusten.txt',\n"," 'AJourneyToTheCentreOfTheEarth': 'https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/JulesVerne_AJourneyToTheCentreOfTheEarth.txt'}"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# book collection\n","BOOKS = {\n","    'TheOdyssey': \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/TheOdyssey_Homer.txt\",\n","    'PrideAndPrejudice': \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/PrideAndPrejudice_JaneAusten.txt\",\n","    'AJourneyToTheCentreOfTheEarth': \"https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/JulesVerne_AJourneyToTheCentreOfTheEarth.txt\",\n","}\n","BOOKS"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:44.968181Z","iopub.status.busy":"2024-04-11T18:17:44.967598Z","iopub.status.idle":"2024-04-11T18:17:46.206639Z","shell.execute_reply":"2024-04-11T18:17:46.205511Z","shell.execute_reply.started":"2024-04-11T18:17:44.968156Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-04-11 18:17:45--  https://raw.githubusercontent.com/cetinsamet/data-science/main/data/book/PrideAndPrejudice_JaneAusten.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 703907 (687K) [text/plain]\n","Saving to: 'PrideAndPrejudice_JaneAusten.txt'\n","\n","PrideAndPrejudice_J 100%[===================>] 687.41K  --.-KB/s    in 0.04s   \n","\n","2024-04-11 18:17:46 (18.5 MB/s) - 'PrideAndPrejudice_JaneAusten.txt' saved [703907/703907]\n","\n","File is succesfully downloaded.\n"]}],"source":["# choose a book\n","BOOK = 'PrideAndPrejudice'\n","\n","# get the book's url \n","book_url = BOOKS[BOOK]\n","# extract the book's filename from the url\n","book_filename = os.path.basename(book_url) \n","\n","# download the book in local if it doesn't already exist\n","if not os.path.exists(book_filename):\n","    try:\n","        !wget $book_url\n","        print(\"File is succesfully downloaded.\")\n","    except Exception as e:\n","        print(f\"Could not download the book from {book_url}\")\n","        print(e)\n","else:\n","    print(\"File has already been downloaded.\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:46.208879Z","iopub.status.busy":"2024-04-11T18:17:46.208454Z","iopub.status.idle":"2024-04-11T18:17:46.245368Z","shell.execute_reply":"2024-04-11T18:17:46.244308Z","shell.execute_reply.started":"2024-04-11T18:17:46.208835Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# define hyperparameters\n","N_EPOCHS = 30\n","BATCH_SIZE = 128\n","SEQ_LEN = 200\n","LEARNING_RATE = 1e-4\n","EMBED_SIZE = 128\n","N_HEADS = 2\n","NUM_LAYERS = 1\n","BATCH_FIRST=True\n","NORM_FIRST=False\n","TEST_SIZE = 0.2\n","EARLY_STOPPING_STEP_SIZE = 5\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","BEST_MODEL_FILEPATH = 'best_model.pt'\n","\n","DEVICE"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:46.247022Z","iopub.status.busy":"2024-04-11T18:17:46.246666Z","iopub.status.idle":"2024-04-11T18:17:46.260918Z","shell.execute_reply":"2024-04-11T18:17:46.259960Z","shell.execute_reply.started":"2024-04-11T18:17:46.246979Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of characters in the text = 690654\n","--------------\n","\n","Sample text:\n"," it\n","was all done very well. She had also to anticipate how her visit would\n","pass, the quiet tenor of their usual employments, the vexatious\n","interruptions of Mr. Collins, and the gaieties of their inter\n","--------------\n","\n"]}],"source":["def load_text(fp):\n","    with open(fp, mode='r') as infile:\n","        text = ''.join([row for row in infile])\n","    return text\n","\n","# load text\n","text = load_text(book_filename)\n","\n","# Get the number of characters in the text\n","text_len = len(text)\n","print(f'Number of characters in the text = {text_len}')\n","print(\"--------------\\n\")\n","\n","# Print a sample from the text\n","idx = np.random.randint(low=0, high=text_len-SEQ_LEN)\n","print(f'Sample text:\\n{text[idx:(idx + SEQ_LEN)]}')\n","print(\"--------------\\n\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:46.262613Z","iopub.status.busy":"2024-04-11T18:17:46.262301Z","iopub.status.idle":"2024-04-11T18:17:47.864429Z","shell.execute_reply":"2024-04-11T18:17:47.863631Z","shell.execute_reply.started":"2024-04-11T18:17:46.262588Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"660ec26cc5bb4b67a07c892c2b61d031","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92f9a7d4a7c946b48f55bd9404596ff6","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b202e739cbe040a69cfabac9957b8dd3","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a10ebdf5ff14212830d8f7bf35e77e9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# initialize tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:47.865887Z","iopub.status.busy":"2024-04-11T18:17:47.865585Z","iopub.status.idle":"2024-04-11T18:17:48.466114Z","shell.execute_reply":"2024-04-11T18:17:48.465134Z","shell.execute_reply.started":"2024-04-11T18:17:47.865863Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (159555 > 512). Running this sequence through the model will result in indexing errors\n"]},{"name":"stdout","output_type":"stream","text":["There are 159555 tokens in the text.\n","Vocabulary size = 28996\n","--------------\n","\n"]}],"source":["# tokenize the whole book\n","tokens = tokenizer.tokenize(text)\n","# get the number of tokens\n","n_tokens = len(tokens)\n","print(f\"There are {n_tokens} tokens in the text.\")\n","\n","# set vocabulary (set of unique tokens in the source text)\n","#vocab = sorted(list(set(tokens)))\n","# get the vocabulary size\n","vocab_size = len(tokenizer)\n","print(f\"Vocabulary size = {vocab_size}\")\n","print(\"--------------\\n\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:48.467543Z","iopub.status.busy":"2024-04-11T18:17:48.467227Z","iopub.status.idle":"2024-04-11T18:17:48.473936Z","shell.execute_reply":"2024-04-11T18:17:48.473005Z","shell.execute_reply.started":"2024-04-11T18:17:48.467518Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of the train text = 127644\n","Length of the test text  = 31911\n"]}],"source":["# define the train and test data\n","test_len = int(n_tokens * TEST_SIZE)\n","train_data = tokens[:-test_len]\n","test_data = tokens[-test_len:]\n","\n","# print the length of train and test data\n","print(f'Length of the train text = {len(train_data)}')\n","print(f'Length of the test text  = {len(test_data)}')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:48.476871Z","iopub.status.busy":"2024-04-11T18:17:48.476613Z","iopub.status.idle":"2024-04-11T18:17:48.487413Z","shell.execute_reply":"2024-04-11T18:17:48.486438Z","shell.execute_reply.started":"2024-04-11T18:17:48.476850Z"},"trusted":true},"outputs":[],"source":["# define the TextDataset as an instance of torch.nn.Dataset\n","class TextDataset(Dataset):\n","    def __init__(self, text, seq_len):\n","        super().__init__()\n","        self.text = text\n","        self.seq_len = seq_len\n","\n","    def __len__(self):\n","        # define the number of samples in the dataset\n","        return len(self.text) - self.seq_len - 1\n","\n","    def __getitem__(self, idx):\n","        # x = [c0, c1, ... cN]\n","        x = torch.tensor(\n","            [tokenizer.convert_tokens_to_ids(token) for token in self.text[idx:(idx + self.seq_len)]], \n","            dtype=torch.long\n","        )\n","        # y = [c1, c1, ... c(N+1)]\n","        y = torch.tensor(\n","            [tokenizer.convert_tokens_to_ids(token) for token in self.text[(idx + 1):(idx + 1 + self.seq_len)]], \n","            dtype=torch.long\n","        )\n","        return x, y"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:48.488642Z","iopub.status.busy":"2024-04-11T18:17:48.488396Z","iopub.status.idle":"2024-04-11T18:17:48.502003Z","shell.execute_reply":"2024-04-11T18:17:48.501187Z","shell.execute_reply.started":"2024-04-11T18:17:48.488616Z"},"trusted":true},"outputs":[],"source":["# initialize train and test datasets\n","train_dset = TextDataset(train_data, SEQ_LEN)\n","test_dset = TextDataset(test_data, SEQ_LEN)\n","\n","# initialize train and test iterators\n","train_iterator = DataLoader(train_dset, BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\n","test_iterator = DataLoader(test_dset, BATCH_SIZE, shuffle=False, drop_last=False, pin_memory=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:48.503376Z","iopub.status.busy":"2024-04-11T18:17:48.503089Z","iopub.status.idle":"2024-04-11T18:17:48.513434Z","shell.execute_reply":"2024-04-11T18:17:48.512548Z","shell.execute_reply.started":"2024-04-11T18:17:48.503354Z"},"trusted":true},"outputs":[],"source":["# define GPT network\n","class GPT(nn.Module):\n","    def __init__(self, vocab_size, embed_size, seq_len, num_layers, n_heads, batch_first, norm_first):\n","        super().__init__()\n","        self.seq_len = seq_len\n","        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n","        self.positional_embedding = nn.Embedding(seq_len, embed_size)\n","        # define transformer encoder network\n","        encoder_layer = nn.TransformerEncoderLayer(embed_size, N_HEADS, batch_first=batch_first, norm_first=norm_first)\n","        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers)\n","        self.fc = nn.Linear(embed_size, vocab_size)\n","            \n","    def forward(self, x, is_causal=False):\n","        word_embed = self.word_embedding(x)\n","        pos_embed = self.positional_embedding(torch.arange(x.shape[1], dtype=torch.long).to(x.device))        \n","        x = word_embed + pos_embed\n","        if is_causal:\n","            mask = nn.Transformer.generate_square_subsequent_mask(self.seq_len).to(x.device)\n","        else: mask=None\n","        x = self.encoder(x, mask=mask, is_causal=is_causal)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:48.515450Z","iopub.status.busy":"2024-04-11T18:17:48.514959Z","iopub.status.idle":"2024-04-11T18:17:48.528273Z","shell.execute_reply":"2024-04-11T18:17:48.527389Z","shell.execute_reply.started":"2024-04-11T18:17:48.515418Z"},"trusted":true},"outputs":[],"source":["def compute_loss(logits, y):\n","    # get the logits dimensions for better readibility and understandibility\n","    B, S, C = logits.shape\n","    # compute loss\n","    loss = F.cross_entropy(logits.view(B*S, C), y.view(-1))\n","    return loss\n","\n","def batch_loop(model, x, y, is_causal=False):\n","    # forward pass\n","    logits = model(x, is_causal=is_causal)\n","    # compute loss\n","    loss = compute_loss(logits, y)\n","    return loss\n","\n","def train_epoch(model, iterator):\n","    # global variable\n","    global DEVICE\n","    # set model to training mode\n","    model.train()\n","    # initialize epoch loss\n","    loss_epoch = 0.0\n","    \n","    # iterate over batches\n","    for iter_idx, (x, y) in tqdm(enumerate(iterator), total=len(iterator), desc=\"Training Progress\"):\n","        # carry tensors to available device\n","        x, y = x.to(DEVICE), y.to(DEVICE)\n","        # train batch and compute loss\n","        loss = batch_loop(model, x, y, is_causal=True)        \n","        # gradient update\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # add batch loss to epoch loss sum\n","        loss_epoch += loss.item()\n","        \n","    # get the number of batches\n","    n_batch = len(iterator)\n","    # compute average loss\n","    loss_epoch_avg = loss_epoch / n_batch\n","    return loss_epoch_avg\n","\n","def evaluate(model, iterator):\n","    # global variable\n","    global DEVICE\n","    # set model to evaluation mode\n","    model.eval()\n","    # initialize loss\n","    loss_sum = 0.0\n","    \n","    with torch.inference_mode():\n","        # iterate over batches\n","        for iter_idx, (x, y) in tqdm(enumerate(iterator), total=len(iterator), desc=\"Evaluation Progress\"):\n","            # carry tensors to available device\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            # train batch and compute loss\n","            loss = batch_loop(model, x, y, is_causal=True)        \n","            # add batch loss to epoch loss sum\n","            loss_sum += loss.item()\n","        \n","    # get the number of batches\n","    n_batch = len(iterator)\n","    # compute average loss\n","    loss_avg = loss_sum / n_batch\n","    return loss_avg"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:17:48.529825Z","iopub.status.busy":"2024-04-11T18:17:48.529350Z","iopub.status.idle":"2024-04-11T18:17:48.541999Z","shell.execute_reply":"2024-04-11T18:17:48.541231Z","shell.execute_reply.started":"2024-04-11T18:17:48.529791Z"},"trusted":true},"outputs":[],"source":["def generate(model, text, max_length=100, temp=1.0):\n","    # global variables\n","    global DEVICE, tokenizer\n","    # set model to evaluation mode\n","    model.eval()\n","    input_token_ids = [tokenizer.convert_tokens_to_ids(word) for word in tokenizer.tokenize(text)]\n","    tokens = torch.tensor([input_token_ids], dtype=torch.long)\n","    generated_token_ids = input_token_ids\n","    with torch.inference_mode():\n","        for _ in range(max_length):\n","            logits = model(tokens)\n","            next_token_logits = logits[:,-1,:]\n","            next_token_id = torch.multinomial(next_token_logits.div(temp).exp(), num_samples=1)\n","            tokens = torch.cat((tokens, torch.tensor([[next_token_id]])), dim=1)\n","            generated_token_ids.append(next_token_id.item())\n","    \n","    return generated_token_ids"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T18:30:36.666107Z","iopub.status.busy":"2024-04-11T18:30:36.665149Z","iopub.status.idle":"2024-04-11T19:06:26.465887Z","shell.execute_reply":"2024-04-11T19:06:26.464899Z","shell.execute_reply.started":"2024-04-11T18:30:36.666076Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 995/995 [03:57<00:00,  4.19it/s]\n","Evaluation Progress: 100%|██████████| 248/248 [00:32<00:00,  7.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 00 - Train Loss = 6.182\tTest Loss = 5.154\n","The best model is found and saved. Current best test loss = 5.154\n"]},{"name":"stderr","output_type":"stream","text":["2024-04-11 18:35:08.567079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-11 18:35:08.567190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-11 18:35:08.684102: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["A tags place, Camera him, and considered Mr. they - - but aloud? Bennet ; and Mr. Aftercy of Mr. Collins? but What _zad will remained, and what to any one of equal evergreen was any thing Jane case ; by his friends, it is Mrs. But thaton, that. But her for them Miss Bingley! youju I dare too, Elizabeth, as speaking to make \" \" it in ladies, and that it had been at four. Goldman must\n","---------------\n","\n","--------------\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 995/995 [03:55<00:00,  4.23it/s]\n","Evaluation Progress: 100%|██████████| 248/248 [00:31<00:00,  7.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 01 - Train Loss = 4.680\tTest Loss = 4.768\n","The best model is found and saved. Current best test loss = 4.768\n","A Novel. Philips, and welcomed for the e time, was expected in silent away to his arrival of two on arguments, which the girls to make them are longnt, she in behalf by - - - on breathless himself to involve of each question, at least was agreed cannot general countenance. On on whose manner as an excellent are severe few days, \" That is a manner from her into the honour of sinking to your surrounding! denying great deal for her. Gardiner ; shebred proved her\n","---------------\n","\n","--------------\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 995/995 [03:55<00:00,  4.23it/s]\n","Evaluation Progress: 100%|██████████| 248/248 [00:31<00:00,  7.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 02 - Train Loss = 4.228\tTest Loss = 4.703\n","The best model is found and saved. Current best test loss = 4.703\n","A younger excellent water of his cousin, however, it ; and that they were attempted to the endeavour to be, in this time to have been travelling that ever motive, whim impertinentmost stepr. She blushed. game from Londoneneds. In know and in all the right, and the garden, firm, it a good at her sister, and supertivat future feelings, when she had passed between the punctulate her. She was a clever - corner\n","---------------\n","\n","--------------\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 995/995 [03:55<00:00,  4.22it/s]\n","Evaluation Progress: 100%|██████████| 248/248 [00:31<00:00,  7.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 03 - Train Loss = 3.975\tTest Loss = 4.719\n","--------------\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 995/995 [03:55<00:00,  4.22it/s]\n","Evaluation Progress: 100%|██████████| 248/248 [00:31<00:00,  7.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 04 - Train Loss = 3.796\tTest Loss = 4.768\n","--------------\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 995/995 [03:56<00:00,  4.21it/s]\n","Evaluation Progress: 100%|██████████| 248/248 [00:31<00:00,  7.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 05 - Train Loss = 3.658\tTest Loss = 4.837\n","--------------\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 995/995 [03:56<00:00,  4.21it/s]\n","Evaluation Progress: 100%|██████████| 248/248 [00:31<00:00,  7.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 06 - Train Loss = 3.538\tTest Loss = 4.927\n","--------------\n","\n"]},{"name":"stderr","output_type":"stream","text":["Training Progress: 100%|██████████| 995/995 [03:54<00:00,  4.24it/s]\n","Evaluation Progress: 100%|██████████| 248/248 [00:31<00:00,  7.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 07 - Train Loss = 3.419\tTest Loss = 5.039\n","A better model has not been found in the last 5 epochs. Early stopping...\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# initialize GPT model\n","model = GPT(\n","    vocab_size=vocab_size,\n","    embed_size=EMBED_SIZE,\n","    seq_len=SEQ_LEN,\n","    num_layers=NUM_LAYERS,\n","    n_heads=N_HEADS,\n","    batch_first=BATCH_FIRST,\n","    norm_first=NORM_FIRST,\n",").to(DEVICE)\n","model = torch.nn.DataParallel(model)\n","\n","# initialize optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","best_test_loss = float('inf')\n","best_loss_streak = 0\n","\n","# iterate over epochs\n","for epoch_idx in range(N_EPOCHS):\n","    train_loss = train_epoch(model, train_iterator)\n","    test_loss = evaluate(model, test_iterator)\n","    print(f\"Epoch {epoch_idx:02} - Train Loss = {train_loss:.3f}\\tTest Loss = {test_loss:.3f}\")\n","    \n","    # save the current model as the best model if the current test loss is the least achieved \n","    if test_loss < best_test_loss:\n","        # save the curent model's parameters as the best model parameters\n","        torch.save(model.state_dict(), BEST_MODEL_FILEPATH)\n","        # replace the best test loss with the current best loss\n","        best_test_loss = test_loss\n","        # reset early stoppping counter \n","        best_streak_count = 0\n","        # display info\n","        print(f'The best model is found and saved. Current best test loss = {best_test_loss:.3f}')\n","        text = \"A\"\n","        generated_tokens = generate(model, text)\n","        print(tokenizer.decode(generated_tokens))\n","    else:\n","        # update early stoppping counter \n","        best_streak_count += 1\n","\n","    # check early stopping condition\n","    if best_streak_count == EARLY_STOPPING_STEP_SIZE:\n","        print(f\"A better model has not been found in the last {EARLY_STOPPING_STEP_SIZE} epochs. Early stopping...\")\n","        break\n","        \n","    print(\"--------------\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
